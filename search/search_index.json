{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"toshi-hazard-store \u00b6 plugin export module for openquake to manage hazard data in dynamodb. Documentation: https://GNS-Science.github.io/toshi-hazard-store GitHub: https://github.com/GNS-Science/toshi-hazard-store PyPI: https://pypi.org/project/toshi-hazard-store/ Free software: GPL-3.0-only Features \u00b6 TODO Credits \u00b6 This package was created with Cookiecutter and the waynerv/cookiecutter-pypackage project template.","title":"Home"},{"location":"#toshi-hazard-store","text":"plugin export module for openquake to manage hazard data in dynamodb. Documentation: https://GNS-Science.github.io/toshi-hazard-store GitHub: https://github.com/GNS-Science/toshi-hazard-store PyPI: https://pypi.org/project/toshi-hazard-store/ Free software: GPL-3.0-only","title":"toshi-hazard-store"},{"location":"#features","text":"TODO","title":"Features"},{"location":"#credits","text":"This package was created with Cookiecutter and the waynerv/cookiecutter-pypackage project template.","title":"Credits"},{"location":"api/","text":"Top-level package for toshi-hazard-store. config \u00b6 This module exports comfiguration for the current system. boolean_env ( environ_name , default = 'FALSE' ) \u00b6 Helper function. Source code in toshi_hazard_store/config.py 6 7 8 def boolean_env ( environ_name : str , default : str = 'FALSE' ) -> bool : \"\"\"Helper function.\"\"\" return bool ( os . getenv ( environ_name , default ) . upper () in [ \"1\" , \"Y\" , \"YES\" , \"TRUE\" ]) model \u00b6 This module defines the pynamodb tables used to store openquake data. IMTValuesAttribute \u00b6 Bases: MapAttribute Store the IntensityMeasureType e.g.(PGA, SA(N)) and the levels and values lists. Source code in toshi_hazard_store/model.py 83 84 85 86 87 88 class IMTValuesAttribute ( MapAttribute ): \"\"\"Store the IntensityMeasureType e.g.(PGA, SA(N)) and the levels and values lists.\"\"\" imt = UnicodeAttribute () lvls = ListAttribute ( of = NumberAttribute ) vals = ListAttribute ( of = NumberAttribute ) LevelValuePairAttribute \u00b6 Bases: MapAttribute Store the IMT level and the POE value at the level. Source code in toshi_hazard_store/model.py 55 56 57 58 59 class LevelValuePairAttribute ( MapAttribute ): \"\"\"Store the IMT level and the POE value at the level.\"\"\" lvl = NumberAttribute ( null = False ) val = NumberAttribute ( null = False ) ToshiOpenquakeHazardCurveRlzs \u00b6 Bases: Model Stores the individual hazard realisation curves. Source code in toshi_hazard_store/model.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 class ToshiOpenquakeHazardCurveRlzs ( Model ): \"\"\"Stores the individual hazard realisation curves.\"\"\" class Meta : billing_mode = 'PAY_PER_REQUEST' table_name = f \"ToshiOpenquakeHazardCurveRlzs- { DEPLOYMENT_STAGE } \" region = REGION if IS_OFFLINE : host = \"http://localhost:8000\" # pragma: no cover haz_sol_id = UnicodeAttribute ( hash_key = True ) imt_loc_rlz_rk = UnicodeAttribute ( range_key = True ) # TODO: check we can actually use this in queries! imt = UnicodeAttribute () loc = UnicodeAttribute () rlz = UnicodeAttribute () values = ListAttribute ( of = LevelValuePairAttribute ) version = VersionAttribute () ToshiOpenquakeHazardCurveRlzsV2 \u00b6 Bases: Model Stores the individual hazard realisation curves. Source code in toshi_hazard_store/model.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 class ToshiOpenquakeHazardCurveRlzsV2 ( Model ): \"\"\"Stores the individual hazard realisation curves.\"\"\" class Meta : \"\"\"DynamoDB Metadata.\"\"\" billing_mode = 'PAY_PER_REQUEST' table_name = f \"ToshiOpenquakeHazardCurveRlzsV2- { DEPLOYMENT_STAGE } \" region = REGION if IS_OFFLINE : host = \"http://localhost:8000\" # pragma: no cover haz_sol_id = UnicodeAttribute ( hash_key = True ) loc_rlz_rk = UnicodeAttribute ( range_key = True ) # TODO: check we can actually use this in queries! loc = UnicodeAttribute () rlz = UnicodeAttribute () values = ListAttribute ( of = IMTValuesAttribute ) version = VersionAttribute () Meta \u00b6 DynamoDB Metadata. Source code in toshi_hazard_store/model.py 94 95 96 97 98 99 100 101 class Meta : \"\"\"DynamoDB Metadata.\"\"\" billing_mode = 'PAY_PER_REQUEST' table_name = f \"ToshiOpenquakeHazardCurveRlzsV2- { DEPLOYMENT_STAGE } \" region = REGION if IS_OFFLINE : host = \"http://localhost:8000\" # pragma: no cover ToshiOpenquakeHazardCurveStats \u00b6 Bases: Model Stores the individual hazard statistical curves. Source code in toshi_hazard_store/model.py 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 class ToshiOpenquakeHazardCurveStats ( Model ): \"\"\"Stores the individual hazard statistical curves.\"\"\" class Meta : \"\"\"DynamoDB Metadata.\"\"\" billing_mode = 'PAY_PER_REQUEST' table_name = f \"ToshiOpenquakeHazardCurveStats- { DEPLOYMENT_STAGE } \" region = REGION if IS_OFFLINE : host = \"http://localhost:8000\" # pragma: no cover haz_sol_id = UnicodeAttribute ( hash_key = True ) imt_loc_agg_rk = UnicodeAttribute ( range_key = True ) imt = UnicodeAttribute () loc = UnicodeAttribute () agg = UnicodeAttribute () values = ListAttribute ( of = LevelValuePairAttribute ) version = VersionAttribute () Meta \u00b6 DynamoDB Metadata. Source code in toshi_hazard_store/model.py 138 139 140 141 142 143 144 145 class Meta : \"\"\"DynamoDB Metadata.\"\"\" billing_mode = 'PAY_PER_REQUEST' table_name = f \"ToshiOpenquakeHazardCurveStats- { DEPLOYMENT_STAGE } \" region = REGION if IS_OFFLINE : host = \"http://localhost:8000\" # pragma: no cover ToshiOpenquakeHazardCurveStatsV2 \u00b6 Bases: Model Stores the individual hazard statistical curves. Source code in toshi_hazard_store/model.py 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 class ToshiOpenquakeHazardCurveStatsV2 ( Model ): \"\"\"Stores the individual hazard statistical curves.\"\"\" class Meta : \"\"\"DynamoDB Metadata.\"\"\" billing_mode = 'PAY_PER_REQUEST' table_name = f \"ToshiOpenquakeHazardCurveStatsV2- { DEPLOYMENT_STAGE } \" region = REGION if IS_OFFLINE : host = \"http://localhost:8000\" # pragma: no cover haz_sol_id = UnicodeAttribute ( hash_key = True ) loc_agg_rk = UnicodeAttribute ( range_key = True ) loc = UnicodeAttribute () agg = UnicodeAttribute () values = ListAttribute ( of = IMTValuesAttribute ) version = VersionAttribute () Meta \u00b6 DynamoDB Metadata. Source code in toshi_hazard_store/model.py 116 117 118 119 120 121 122 123 class Meta : \"\"\"DynamoDB Metadata.\"\"\" billing_mode = 'PAY_PER_REQUEST' table_name = f \"ToshiOpenquakeHazardCurveStatsV2- { DEPLOYMENT_STAGE } \" region = REGION if IS_OFFLINE : host = \"http://localhost:8000\" # pragma: no cover ToshiOpenquakeHazardMeta \u00b6 Bases: Model Stores metadata from the job configuration and the oq HDF5. Source code in toshi_hazard_store/model.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 class ToshiOpenquakeHazardMeta ( Model ): \"\"\"Stores metadata from the job configuration and the oq HDF5.\"\"\" class Meta : \"\"\"DynamoDB Metadata.\"\"\" billing_mode = 'PAY_PER_REQUEST' table_name = f \"ToshiOpenquakeHazardMeta- { DEPLOYMENT_STAGE } \" region = REGION if IS_OFFLINE : host = \"http://localhost:8000\" # pragma: no cover partition_key = UnicodeAttribute ( hash_key = True ) # a static value as we actually don't want to partition our data hazsol_vs30_rk = UnicodeAttribute ( range_key = True ) updated = UTCDateTimeAttribute () version = VersionAttribute () # known at configuration haz_sol_id = UnicodeAttribute () vs30 = NumberAttribute () # vs30 value imts = UnicodeSetAttribute () # list of IMTs locs = UnicodeSetAttribute () # list of Location codes srcs = UnicodeSetAttribute () # list of source model ids aggs = UnicodeSetAttribute () # list of aggregration/quantile ids e.g. \"0.1. 0.5, mean, 0.9\" inv_time = NumberAttribute () # Invesigation time in years # extracted from the OQ HDF5 src_lt = JSONAttribute () # sources meta as DataFrame JSON gsim_lt = JSONAttribute () # gmpe meta as DataFrame JSON rlz_lt = JSONAttribute () # realization meta as DataFrame JSON Meta \u00b6 DynamoDB Metadata. Source code in toshi_hazard_store/model.py 25 26 27 28 29 30 31 32 class Meta : \"\"\"DynamoDB Metadata.\"\"\" billing_mode = 'PAY_PER_REQUEST' table_name = f \"ToshiOpenquakeHazardMeta- { DEPLOYMENT_STAGE } \" region = REGION if IS_OFFLINE : host = \"http://localhost:8000\" # pragma: no cover drop_tables () \u00b6 Drop the tables, if they exist. Source code in toshi_hazard_store/model.py 176 177 178 179 180 181 def drop_tables (): \"\"\"Drop the tables, if they exist.\"\"\" for table in tables : if table . exists (): # pragma: no cover table . delete_table () log . info ( f 'deleted table: { table } ' ) migrate () \u00b6 Create the tables, unless they exist already. Source code in toshi_hazard_store/model.py 167 168 169 170 171 172 173 def migrate (): \"\"\"Create the tables, unless they exist already.\"\"\" for table in tables : if not table . exists (): # pragma: no cover table . create_table ( wait = True ) print ( f \"Migrate created table: { table } \" ) log . info ( f \"Migrate created table: { table } \" ) query \u00b6 Queries for saving and retrieving openquake hazard results with convenience. batch_save_hcurve_rlzs ( toshi_id , models ) \u00b6 Save list of ToshiOpenquakeHazardCurveRlzs updating hash and range keys. Source code in toshi_hazard_store/query.py 16 17 18 19 20 21 22 def batch_save_hcurve_rlzs ( toshi_id : str , models : Iterable [ model . ToshiOpenquakeHazardCurveRlzs ]) -> None : \"\"\"Save list of ToshiOpenquakeHazardCurveRlzs updating hash and range keys.\"\"\" with model . ToshiOpenquakeHazardCurveRlzs . batch_write () as batch : for item in models : item . haz_sol_id = toshi_id item . imt_loc_rlz_rk = f \" { item . imt } : { item . loc } : { item . rlz } \" batch . save ( item ) batch_save_hcurve_rlzs_v2 ( toshi_id , models ) \u00b6 Save list of ToshiOpenquakeHazardCurveRlzsV2 updating hash and range keys. Source code in toshi_hazard_store/query.py 25 26 27 28 29 30 31 def batch_save_hcurve_rlzs_v2 ( toshi_id : str , models : Iterable [ model . ToshiOpenquakeHazardCurveRlzsV2 ]) -> None : \"\"\"Save list of ToshiOpenquakeHazardCurveRlzsV2 updating hash and range keys.\"\"\" with model . ToshiOpenquakeHazardCurveRlzsV2 . batch_write () as batch : for item in models : item . haz_sol_id = toshi_id item . loc_rlz_rk = f \" { item . loc } : { item . rlz } \" batch . save ( item ) batch_save_hcurve_stats ( toshi_id , models ) \u00b6 Save list of ToshiOpenquakeHazardCurveStats updating hash and range keys. Source code in toshi_hazard_store/query.py 7 8 9 10 11 12 13 def batch_save_hcurve_stats ( toshi_id : str , models : Iterable [ model . ToshiOpenquakeHazardCurveStats ]) -> None : \"\"\"Save list of ToshiOpenquakeHazardCurveStats updating hash and range keys.\"\"\" with model . ToshiOpenquakeHazardCurveStats . batch_write () as batch : for item in models : item . haz_sol_id = toshi_id item . imt_loc_agg_rk = f \" { item . imt } : { item . loc } : { item . agg } \" batch . save ( item ) batch_save_hcurve_stats_v2 ( toshi_id , models ) \u00b6 Save list of ToshiOpenquakeHazardCurveRlzsV2 updating hash and range keys. Source code in toshi_hazard_store/query.py 34 35 36 37 38 39 40 def batch_save_hcurve_stats_v2 ( toshi_id : str , models : Iterable [ model . ToshiOpenquakeHazardCurveStatsV2 ]) -> None : \"\"\"Save list of ToshiOpenquakeHazardCurveRlzsV2 updating hash and range keys.\"\"\" with model . ToshiOpenquakeHazardCurveStatsV2 . batch_write () as batch : for item in models : item . haz_sol_id = toshi_id item . loc_agg_rk = f \" { item . loc } : { item . agg } \" batch . save ( item ) get_hazard_metadata ( haz_sol_ids = None , vs30_vals = None ) \u00b6 Fetch ToshiOpenquakeHazardMeta based on criteria. Source code in toshi_hazard_store/query.py 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 def get_hazard_metadata ( haz_sol_ids : Iterable [ str ] = None , vs30_vals : Iterable [ int ] = None , ) -> Iterator [ mOHM ]: \"\"\"Fetch ToshiOpenquakeHazardMeta based on criteria.\"\"\" condition_expr = None if haz_sol_ids : condition_expr = condition_expr & mOHM . haz_sol_id . is_in ( * haz_sol_ids ) if vs30_vals : condition_expr = condition_expr & mOHM . vs30 . is_in ( * vs30_vals ) for hit in model . ToshiOpenquakeHazardMeta . query ( \"ToshiOpenquakeHazardMeta\" , filter_condition = condition_expr # NB the partition key is the table name! ): yield ( hit ) get_hazard_rlz_curves ( haz_sol_id , imts = None , locs = None , rlzs = None ) \u00b6 Use ToshiOpenquakeHazardCurveRlzs.imt_loc_agg_rk range key as much as possible. Source code in toshi_hazard_store/query.py 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 def get_hazard_rlz_curves ( haz_sol_id : str , imts : Iterable [ str ] = None , locs : Iterable [ str ] = None , rlzs : Iterable [ str ] = None , ) -> Iterator [ mOHCR ]: \"\"\"Use ToshiOpenquakeHazardCurveRlzs.imt_loc_agg_rk range key as much as possible.\"\"\" range_key_first_val = \"\" condition_expr = None if imts : first_imt = sorted ( imts )[ 0 ] range_key_first_val += f \" { first_imt } \" condition_expr = condition_expr & mOHCR . imt . is_in ( * imts ) if locs : condition_expr = condition_expr & mOHCR . loc . is_in ( * locs ) if rlzs : condition_expr = condition_expr & mOHCR . rlz . is_in ( * rlzs ) if imts and locs : first_loc = sorted ( locs )[ 0 ] range_key_first_val += f \": { first_loc } \" if imts and locs and rlzs : first_rlz = sorted ( rlzs )[ 0 ] range_key_first_val += f \": { first_rlz } \" print ( f \"range_key_first_val: { range_key_first_val } \" ) print ( condition_expr ) if range_key_first_val : qry = mOHCR . query ( haz_sol_id , mOHCR . imt_loc_rlz_rk >= range_key_first_val , filter_condition = condition_expr ) else : qry = mOHCR . query ( haz_sol_id , mOHCR . imt_loc_rlz_rk >= \" \" , # lowest printable char in ascii table is SPACE. (NULL is first control) filter_condition = condition_expr , ) print ( f \"get_hazard_rlz_curves: qry { qry } \" ) for hit in qry : yield ( hit ) get_hazard_rlz_curves_v2 ( haz_sol_id , imts = [], locs = [], rlzs = []) \u00b6 Use mOHCR2.loc_agg_rk range key as much as possible. Source code in toshi_hazard_store/query.py 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 def get_hazard_rlz_curves_v2 ( haz_sol_id : str , imts : Iterable [ str ] = [], locs : Iterable [ str ] = [], rlzs : Iterable [ str ] = [], ) -> Iterator [ mOHCR2 ]: \"\"\"Use mOHCR2.loc_agg_rk range key as much as possible.\"\"\" range_key_first_val = \"\" condition_expr = None # if imts: # first_imt = sorted(imts)[0] # range_key_first_val += f\"{first_imt}\" # condition_expr = condition_expr & mOHCR.imt.is_in(*imts) if locs : condition_expr = condition_expr & mOHCR2 . loc . is_in ( * locs ) if rlzs : condition_expr = condition_expr & mOHCR2 . rlz . is_in ( * rlzs ) if locs : first_loc = sorted ( locs )[ 0 ] range_key_first_val += f \" { first_loc } \" if locs and rlzs : first_rlz = sorted ( rlzs )[ 0 ] range_key_first_val += f \": { first_rlz } \" print ( f \"range_key_first_val: { range_key_first_val } \" ) print ( condition_expr ) if range_key_first_val : qry = mOHCR2 . query ( haz_sol_id , mOHCR2 . loc_rlz_rk >= range_key_first_val , filter_condition = condition_expr ) else : qry = mOHCR2 . query ( haz_sol_id , mOHCR2 . loc_rlz_rk >= \" \" , # lowest printable char in ascii table is SPACE. (NULL is first control) filter_condition = condition_expr , ) print ( f \"get_hazard_rlz_curves_v2: qry { qry } \" ) for hit in qry : if imts : hit . values = list ( filter ( lambda x : x . imt in imts , hit . values )) yield ( hit ) get_hazard_stats_curves ( haz_sol_id , imts = None , locs = None , aggs = None ) \u00b6 Use ToshiOpenquakeHazardCurveStats.imt_loc_agg_rk range key as much as possible. Source code in toshi_hazard_store/query.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 def get_hazard_stats_curves ( haz_sol_id : str , imts : Iterable [ str ] = None , locs : Iterable [ str ] = None , aggs : Iterable [ str ] = None , ) -> Iterator [ mOHCS ]: \"\"\"Use ToshiOpenquakeHazardCurveStats.imt_loc_agg_rk range key as much as possible.\"\"\" range_key_first_val = \"\" condition_expr = None if imts : first_imt = sorted ( imts )[ 0 ] range_key_first_val += f \" { first_imt } \" condition_expr = condition_expr & mOHCS . imt . is_in ( * imts ) if locs : condition_expr = condition_expr & mOHCS . loc . is_in ( * locs ) if aggs : condition_expr = condition_expr & mOHCS . agg . is_in ( * aggs ) if imts and locs : first_loc = sorted ( locs )[ 0 ] range_key_first_val += f \": { first_loc } \" if imts and locs and aggs : first_agg = sorted ( aggs )[ 0 ] range_key_first_val += f \": { first_agg } \" print ( f \"range_key_first_val: { range_key_first_val } \" ) print ( condition_expr ) if range_key_first_val : qry = mOHCS . query ( haz_sol_id , mOHCS . imt_loc_agg_rk >= range_key_first_val , filter_condition = condition_expr ) else : qry = mOHCS . query ( haz_sol_id , mOHCS . imt_loc_agg_rk >= \" \" , # lowest printable char in ascii table is SPACE. (NULL is first control) filter_condition = condition_expr , ) print ( f \"get_hazard_stats_curves: qry { qry } \" ) for hit in qry : yield ( hit ) get_hazard_stats_curves_v2 ( haz_sol_id , imts = [], locs = [], aggs = []) \u00b6 Use mOHCS2.loc_agg_rk range key as much as possible. Source code in toshi_hazard_store/query.py 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 def get_hazard_stats_curves_v2 ( haz_sol_id : str , imts : Iterable [ str ] = [], locs : Iterable [ str ] = [], aggs : Iterable [ str ] = [], ) -> Iterator [ mOHCS2 ]: \"\"\"Use mOHCS2.loc_agg_rk range key as much as possible.\"\"\" range_key_first_val = \"\" condition_expr = None if locs : condition_expr = condition_expr & mOHCS2 . loc . is_in ( * locs ) if aggs : condition_expr = condition_expr & mOHCS2 . agg . is_in ( * aggs ) if locs : first_loc = sorted ( locs )[ 0 ] range_key_first_val += f \" { first_loc } \" if locs and aggs : first_agg = sorted ( aggs )[ 0 ] range_key_first_val += f \": { first_agg } \" print ( f \"range_key_first_val: { range_key_first_val } \" ) print ( condition_expr ) if range_key_first_val : qry = mOHCS2 . query ( haz_sol_id , mOHCS2 . loc_agg_rk >= range_key_first_val , filter_condition = condition_expr ) else : qry = mOHCS2 . query ( haz_sol_id , mOHCS2 . loc_agg_rk >= \" \" , # lowest printable char in ascii table is SPACE. (NULL is first control) filter_condition = condition_expr , ) print ( f \"get_hazard_stats_curves_v2: qry { qry } \" ) for hit in qry : if imts : hit . values = list ( filter ( lambda x : x . imt in imts , hit . values )) yield ( hit ) transform \u00b6 Helper functions to export an openquake calculation and save it with toshi-hazard-store. export_meta ( toshi_id , dstore ) \u00b6 Extract and same the meta data. Source code in toshi_hazard_store/transform.py 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 def export_meta ( toshi_id , dstore ): \"\"\"Extract and same the meta data.\"\"\" oq = dstore [ 'oqparam' ] sitemesh = get_sites ( dstore [ 'sitecol' ]) source_lt , gsim_lt , rlz_lt = parse_logic_tree_branches ( dstore . filename ) quantiles = [ str ( q ) for q in vars ( oq )[ 'quantiles' ]] + [ 'mean' ] # mean is default, other values come from the config df_len = 0 df_len += len ( source_lt . to_json ()) df_len += len ( gsim_lt . to_json ()) df_len += len ( rlz_lt . to_json ()) if df_len >= 300e3 : print ( 'WARNING: Dataframes for this job may be too large to store on DynamoDB.' ) obj = model . ToshiOpenquakeHazardMeta ( partition_key = \"ToshiOpenquakeHazardMeta\" , updated = dt . datetime . now ( tzutc ()), vs30 = oq . reference_vs30_value , # vs30 value haz_sol_id = toshi_id , imts = list ( oq . imtls . keys ()), # list of IMTs locs = [ tup [ 0 ] . decode () for tup in sitemesh . tolist ()], # list of Location codes # important configuration arguments aggs = quantiles , inv_time = vars ( oq )[ 'investigation_time' ], src_lt = source_lt . to_json (), # sources meta as DataFrame JSON gsim_lt = gsim_lt . to_json (), # gmpe meta as DataFrame JSON rlz_lt = rlz_lt . to_json (), # realization meta as DataFrame JSON ) obj . hazsol_vs30_rk = f \" { obj . haz_sol_id } : { obj . vs30 } \" obj . save () parse_logic_tree_branches ( file_id ) \u00b6 Extract the dataframes. Source code in toshi_hazard_store/transform.py 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 def parse_logic_tree_branches ( file_id ): \"\"\"Extract the dataframes.\"\"\" with h5py . File ( file_id ) as hf : # read and prepare the source model logic tree for documentation ### full_lt is a key that contains subkeys for each type of logic tree ### here we read the contents of source_model_lt into a dataframe source_lt = pd . DataFrame ( hf [ 'full_lt' ][ 'source_model_lt' ][:]) for col in source_lt . columns [: - 1 ]: source_lt . loc [:, col ] = source_lt [ col ] . str . decode ( 'ascii' ) # identify the source labels used in the realizations table source_lt . loc [:, 'branch_code' ] = [ x for x in BASE183 [ 0 : len ( source_lt )]] source_lt . set_index ( 'branch_code' , inplace = True ) # read and prepare the gsim logic tree for documentation ### full_lt is a key that contains subkeys for each type of logic tree ### here we read the contents of gsim_lt into a dataframe gsim_lt = pd . DataFrame ( hf [ 'full_lt' ][ 'gsim_lt' ][:]) for col in gsim_lt . columns [: - 1 ]: gsim_lt . loc [:, col ] = gsim_lt . loc [:, col ] . str . decode ( 'ascii' ) # # break up the gsim df into tectonic regions (one df per column of gsims in realization labels. e.g. A~AAA) # # the order of the dictionary is consistent with the order of the columns # gsim_lt_dict = {} # for i, trt in enumerate(np.unique(gsim_lt['trt'])): # df = gsim_lt[gsim_lt['trt'] == trt] # df.loc[:, 'branch_code'] = [x[1] for x in df['branch']] # df.set_index('branch_code', inplace=True) # ### the branch code used to be a user specified string from the gsim logic tree .xml # ### now the only way to identify which regionalization is used is to extract it manually # for j, x in zip(df.index, df['uncertainty']): # tags = re.split('\\\\[|\\\\]|\\nregion = \\\"|\\\"', x) # if len(tags) > 4: # df.loc[j, 'model name'] = f'{tags[1]}_{tags[3]}' # else: # df.loc[j, 'model name'] = tags[1] # gsim_lt_dict[i] = df # read and prep the realization record for documentation ### this one can be read into a df directly from the dstore's full_lt ### the column titled 'ordinal' is dropped, as it will be the same as the 0-n index dstore = datastore . read ( file_id ) rlz_lt = pd . DataFrame ( dstore [ 'full_lt' ] . rlzs ) . drop ( 'ordinal' , axis = 1 ) # # add to the rlt_lt to note which source models and which gsims were used for each branch # for i_rlz in rlz_lt.index: # # rlz name is in the form A~AAA, with a single source identifier followed by characters for each trt region # srm_code, gsim_codes = rlz_lt.loc[i_rlz, 'branch_path'].split('~') # # copy over the source label # rlz_lt.loc[i_rlz, 'source combination'] = source_lt.loc[srm_code, 'branch'] # # loop through the characters for the trt region and add the corresponding gsim name # for i, gsim_code in enumerate(gsim_codes): # trt, gsim = gsim_lt_dict[i].loc[gsim_code, ['trt', 'model name']] # rlz_lt.loc[i_rlz, trt] = gsim return source_lt , gsim_lt , rlz_lt","title":"Modules"},{"location":"api/#toshi_hazard_store.config","text":"This module exports comfiguration for the current system.","title":"config"},{"location":"api/#toshi_hazard_store.config.boolean_env","text":"Helper function. Source code in toshi_hazard_store/config.py 6 7 8 def boolean_env ( environ_name : str , default : str = 'FALSE' ) -> bool : \"\"\"Helper function.\"\"\" return bool ( os . getenv ( environ_name , default ) . upper () in [ \"1\" , \"Y\" , \"YES\" , \"TRUE\" ])","title":"boolean_env()"},{"location":"api/#toshi_hazard_store.model","text":"This module defines the pynamodb tables used to store openquake data.","title":"model"},{"location":"api/#toshi_hazard_store.model.IMTValuesAttribute","text":"Bases: MapAttribute Store the IntensityMeasureType e.g.(PGA, SA(N)) and the levels and values lists. Source code in toshi_hazard_store/model.py 83 84 85 86 87 88 class IMTValuesAttribute ( MapAttribute ): \"\"\"Store the IntensityMeasureType e.g.(PGA, SA(N)) and the levels and values lists.\"\"\" imt = UnicodeAttribute () lvls = ListAttribute ( of = NumberAttribute ) vals = ListAttribute ( of = NumberAttribute )","title":"IMTValuesAttribute"},{"location":"api/#toshi_hazard_store.model.LevelValuePairAttribute","text":"Bases: MapAttribute Store the IMT level and the POE value at the level. Source code in toshi_hazard_store/model.py 55 56 57 58 59 class LevelValuePairAttribute ( MapAttribute ): \"\"\"Store the IMT level and the POE value at the level.\"\"\" lvl = NumberAttribute ( null = False ) val = NumberAttribute ( null = False )","title":"LevelValuePairAttribute"},{"location":"api/#toshi_hazard_store.model.ToshiOpenquakeHazardCurveRlzs","text":"Bases: Model Stores the individual hazard realisation curves. Source code in toshi_hazard_store/model.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 class ToshiOpenquakeHazardCurveRlzs ( Model ): \"\"\"Stores the individual hazard realisation curves.\"\"\" class Meta : billing_mode = 'PAY_PER_REQUEST' table_name = f \"ToshiOpenquakeHazardCurveRlzs- { DEPLOYMENT_STAGE } \" region = REGION if IS_OFFLINE : host = \"http://localhost:8000\" # pragma: no cover haz_sol_id = UnicodeAttribute ( hash_key = True ) imt_loc_rlz_rk = UnicodeAttribute ( range_key = True ) # TODO: check we can actually use this in queries! imt = UnicodeAttribute () loc = UnicodeAttribute () rlz = UnicodeAttribute () values = ListAttribute ( of = LevelValuePairAttribute ) version = VersionAttribute ()","title":"ToshiOpenquakeHazardCurveRlzs"},{"location":"api/#toshi_hazard_store.model.ToshiOpenquakeHazardCurveRlzsV2","text":"Bases: Model Stores the individual hazard realisation curves. Source code in toshi_hazard_store/model.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 class ToshiOpenquakeHazardCurveRlzsV2 ( Model ): \"\"\"Stores the individual hazard realisation curves.\"\"\" class Meta : \"\"\"DynamoDB Metadata.\"\"\" billing_mode = 'PAY_PER_REQUEST' table_name = f \"ToshiOpenquakeHazardCurveRlzsV2- { DEPLOYMENT_STAGE } \" region = REGION if IS_OFFLINE : host = \"http://localhost:8000\" # pragma: no cover haz_sol_id = UnicodeAttribute ( hash_key = True ) loc_rlz_rk = UnicodeAttribute ( range_key = True ) # TODO: check we can actually use this in queries! loc = UnicodeAttribute () rlz = UnicodeAttribute () values = ListAttribute ( of = IMTValuesAttribute ) version = VersionAttribute ()","title":"ToshiOpenquakeHazardCurveRlzsV2"},{"location":"api/#toshi_hazard_store.model.ToshiOpenquakeHazardCurveRlzsV2.Meta","text":"DynamoDB Metadata. Source code in toshi_hazard_store/model.py 94 95 96 97 98 99 100 101 class Meta : \"\"\"DynamoDB Metadata.\"\"\" billing_mode = 'PAY_PER_REQUEST' table_name = f \"ToshiOpenquakeHazardCurveRlzsV2- { DEPLOYMENT_STAGE } \" region = REGION if IS_OFFLINE : host = \"http://localhost:8000\" # pragma: no cover","title":"Meta"},{"location":"api/#toshi_hazard_store.model.ToshiOpenquakeHazardCurveStats","text":"Bases: Model Stores the individual hazard statistical curves. Source code in toshi_hazard_store/model.py 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 class ToshiOpenquakeHazardCurveStats ( Model ): \"\"\"Stores the individual hazard statistical curves.\"\"\" class Meta : \"\"\"DynamoDB Metadata.\"\"\" billing_mode = 'PAY_PER_REQUEST' table_name = f \"ToshiOpenquakeHazardCurveStats- { DEPLOYMENT_STAGE } \" region = REGION if IS_OFFLINE : host = \"http://localhost:8000\" # pragma: no cover haz_sol_id = UnicodeAttribute ( hash_key = True ) imt_loc_agg_rk = UnicodeAttribute ( range_key = True ) imt = UnicodeAttribute () loc = UnicodeAttribute () agg = UnicodeAttribute () values = ListAttribute ( of = LevelValuePairAttribute ) version = VersionAttribute ()","title":"ToshiOpenquakeHazardCurveStats"},{"location":"api/#toshi_hazard_store.model.ToshiOpenquakeHazardCurveStats.Meta","text":"DynamoDB Metadata. Source code in toshi_hazard_store/model.py 138 139 140 141 142 143 144 145 class Meta : \"\"\"DynamoDB Metadata.\"\"\" billing_mode = 'PAY_PER_REQUEST' table_name = f \"ToshiOpenquakeHazardCurveStats- { DEPLOYMENT_STAGE } \" region = REGION if IS_OFFLINE : host = \"http://localhost:8000\" # pragma: no cover","title":"Meta"},{"location":"api/#toshi_hazard_store.model.ToshiOpenquakeHazardCurveStatsV2","text":"Bases: Model Stores the individual hazard statistical curves. Source code in toshi_hazard_store/model.py 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 class ToshiOpenquakeHazardCurveStatsV2 ( Model ): \"\"\"Stores the individual hazard statistical curves.\"\"\" class Meta : \"\"\"DynamoDB Metadata.\"\"\" billing_mode = 'PAY_PER_REQUEST' table_name = f \"ToshiOpenquakeHazardCurveStatsV2- { DEPLOYMENT_STAGE } \" region = REGION if IS_OFFLINE : host = \"http://localhost:8000\" # pragma: no cover haz_sol_id = UnicodeAttribute ( hash_key = True ) loc_agg_rk = UnicodeAttribute ( range_key = True ) loc = UnicodeAttribute () agg = UnicodeAttribute () values = ListAttribute ( of = IMTValuesAttribute ) version = VersionAttribute ()","title":"ToshiOpenquakeHazardCurveStatsV2"},{"location":"api/#toshi_hazard_store.model.ToshiOpenquakeHazardCurveStatsV2.Meta","text":"DynamoDB Metadata. Source code in toshi_hazard_store/model.py 116 117 118 119 120 121 122 123 class Meta : \"\"\"DynamoDB Metadata.\"\"\" billing_mode = 'PAY_PER_REQUEST' table_name = f \"ToshiOpenquakeHazardCurveStatsV2- { DEPLOYMENT_STAGE } \" region = REGION if IS_OFFLINE : host = \"http://localhost:8000\" # pragma: no cover","title":"Meta"},{"location":"api/#toshi_hazard_store.model.ToshiOpenquakeHazardMeta","text":"Bases: Model Stores metadata from the job configuration and the oq HDF5. Source code in toshi_hazard_store/model.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 class ToshiOpenquakeHazardMeta ( Model ): \"\"\"Stores metadata from the job configuration and the oq HDF5.\"\"\" class Meta : \"\"\"DynamoDB Metadata.\"\"\" billing_mode = 'PAY_PER_REQUEST' table_name = f \"ToshiOpenquakeHazardMeta- { DEPLOYMENT_STAGE } \" region = REGION if IS_OFFLINE : host = \"http://localhost:8000\" # pragma: no cover partition_key = UnicodeAttribute ( hash_key = True ) # a static value as we actually don't want to partition our data hazsol_vs30_rk = UnicodeAttribute ( range_key = True ) updated = UTCDateTimeAttribute () version = VersionAttribute () # known at configuration haz_sol_id = UnicodeAttribute () vs30 = NumberAttribute () # vs30 value imts = UnicodeSetAttribute () # list of IMTs locs = UnicodeSetAttribute () # list of Location codes srcs = UnicodeSetAttribute () # list of source model ids aggs = UnicodeSetAttribute () # list of aggregration/quantile ids e.g. \"0.1. 0.5, mean, 0.9\" inv_time = NumberAttribute () # Invesigation time in years # extracted from the OQ HDF5 src_lt = JSONAttribute () # sources meta as DataFrame JSON gsim_lt = JSONAttribute () # gmpe meta as DataFrame JSON rlz_lt = JSONAttribute () # realization meta as DataFrame JSON","title":"ToshiOpenquakeHazardMeta"},{"location":"api/#toshi_hazard_store.model.ToshiOpenquakeHazardMeta.Meta","text":"DynamoDB Metadata. Source code in toshi_hazard_store/model.py 25 26 27 28 29 30 31 32 class Meta : \"\"\"DynamoDB Metadata.\"\"\" billing_mode = 'PAY_PER_REQUEST' table_name = f \"ToshiOpenquakeHazardMeta- { DEPLOYMENT_STAGE } \" region = REGION if IS_OFFLINE : host = \"http://localhost:8000\" # pragma: no cover","title":"Meta"},{"location":"api/#toshi_hazard_store.model.drop_tables","text":"Drop the tables, if they exist. Source code in toshi_hazard_store/model.py 176 177 178 179 180 181 def drop_tables (): \"\"\"Drop the tables, if they exist.\"\"\" for table in tables : if table . exists (): # pragma: no cover table . delete_table () log . info ( f 'deleted table: { table } ' )","title":"drop_tables()"},{"location":"api/#toshi_hazard_store.model.migrate","text":"Create the tables, unless they exist already. Source code in toshi_hazard_store/model.py 167 168 169 170 171 172 173 def migrate (): \"\"\"Create the tables, unless they exist already.\"\"\" for table in tables : if not table . exists (): # pragma: no cover table . create_table ( wait = True ) print ( f \"Migrate created table: { table } \" ) log . info ( f \"Migrate created table: { table } \" )","title":"migrate()"},{"location":"api/#toshi_hazard_store.query","text":"Queries for saving and retrieving openquake hazard results with convenience.","title":"query"},{"location":"api/#toshi_hazard_store.query.batch_save_hcurve_rlzs","text":"Save list of ToshiOpenquakeHazardCurveRlzs updating hash and range keys. Source code in toshi_hazard_store/query.py 16 17 18 19 20 21 22 def batch_save_hcurve_rlzs ( toshi_id : str , models : Iterable [ model . ToshiOpenquakeHazardCurveRlzs ]) -> None : \"\"\"Save list of ToshiOpenquakeHazardCurveRlzs updating hash and range keys.\"\"\" with model . ToshiOpenquakeHazardCurveRlzs . batch_write () as batch : for item in models : item . haz_sol_id = toshi_id item . imt_loc_rlz_rk = f \" { item . imt } : { item . loc } : { item . rlz } \" batch . save ( item )","title":"batch_save_hcurve_rlzs()"},{"location":"api/#toshi_hazard_store.query.batch_save_hcurve_rlzs_v2","text":"Save list of ToshiOpenquakeHazardCurveRlzsV2 updating hash and range keys. Source code in toshi_hazard_store/query.py 25 26 27 28 29 30 31 def batch_save_hcurve_rlzs_v2 ( toshi_id : str , models : Iterable [ model . ToshiOpenquakeHazardCurveRlzsV2 ]) -> None : \"\"\"Save list of ToshiOpenquakeHazardCurveRlzsV2 updating hash and range keys.\"\"\" with model . ToshiOpenquakeHazardCurveRlzsV2 . batch_write () as batch : for item in models : item . haz_sol_id = toshi_id item . loc_rlz_rk = f \" { item . loc } : { item . rlz } \" batch . save ( item )","title":"batch_save_hcurve_rlzs_v2()"},{"location":"api/#toshi_hazard_store.query.batch_save_hcurve_stats","text":"Save list of ToshiOpenquakeHazardCurveStats updating hash and range keys. Source code in toshi_hazard_store/query.py 7 8 9 10 11 12 13 def batch_save_hcurve_stats ( toshi_id : str , models : Iterable [ model . ToshiOpenquakeHazardCurveStats ]) -> None : \"\"\"Save list of ToshiOpenquakeHazardCurveStats updating hash and range keys.\"\"\" with model . ToshiOpenquakeHazardCurveStats . batch_write () as batch : for item in models : item . haz_sol_id = toshi_id item . imt_loc_agg_rk = f \" { item . imt } : { item . loc } : { item . agg } \" batch . save ( item )","title":"batch_save_hcurve_stats()"},{"location":"api/#toshi_hazard_store.query.batch_save_hcurve_stats_v2","text":"Save list of ToshiOpenquakeHazardCurveRlzsV2 updating hash and range keys. Source code in toshi_hazard_store/query.py 34 35 36 37 38 39 40 def batch_save_hcurve_stats_v2 ( toshi_id : str , models : Iterable [ model . ToshiOpenquakeHazardCurveStatsV2 ]) -> None : \"\"\"Save list of ToshiOpenquakeHazardCurveRlzsV2 updating hash and range keys.\"\"\" with model . ToshiOpenquakeHazardCurveStatsV2 . batch_write () as batch : for item in models : item . haz_sol_id = toshi_id item . loc_agg_rk = f \" { item . loc } : { item . agg } \" batch . save ( item )","title":"batch_save_hcurve_stats_v2()"},{"location":"api/#toshi_hazard_store.query.get_hazard_metadata","text":"Fetch ToshiOpenquakeHazardMeta based on criteria. Source code in toshi_hazard_store/query.py 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 def get_hazard_metadata ( haz_sol_ids : Iterable [ str ] = None , vs30_vals : Iterable [ int ] = None , ) -> Iterator [ mOHM ]: \"\"\"Fetch ToshiOpenquakeHazardMeta based on criteria.\"\"\" condition_expr = None if haz_sol_ids : condition_expr = condition_expr & mOHM . haz_sol_id . is_in ( * haz_sol_ids ) if vs30_vals : condition_expr = condition_expr & mOHM . vs30 . is_in ( * vs30_vals ) for hit in model . ToshiOpenquakeHazardMeta . query ( \"ToshiOpenquakeHazardMeta\" , filter_condition = condition_expr # NB the partition key is the table name! ): yield ( hit )","title":"get_hazard_metadata()"},{"location":"api/#toshi_hazard_store.query.get_hazard_rlz_curves","text":"Use ToshiOpenquakeHazardCurveRlzs.imt_loc_agg_rk range key as much as possible. Source code in toshi_hazard_store/query.py 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 def get_hazard_rlz_curves ( haz_sol_id : str , imts : Iterable [ str ] = None , locs : Iterable [ str ] = None , rlzs : Iterable [ str ] = None , ) -> Iterator [ mOHCR ]: \"\"\"Use ToshiOpenquakeHazardCurveRlzs.imt_loc_agg_rk range key as much as possible.\"\"\" range_key_first_val = \"\" condition_expr = None if imts : first_imt = sorted ( imts )[ 0 ] range_key_first_val += f \" { first_imt } \" condition_expr = condition_expr & mOHCR . imt . is_in ( * imts ) if locs : condition_expr = condition_expr & mOHCR . loc . is_in ( * locs ) if rlzs : condition_expr = condition_expr & mOHCR . rlz . is_in ( * rlzs ) if imts and locs : first_loc = sorted ( locs )[ 0 ] range_key_first_val += f \": { first_loc } \" if imts and locs and rlzs : first_rlz = sorted ( rlzs )[ 0 ] range_key_first_val += f \": { first_rlz } \" print ( f \"range_key_first_val: { range_key_first_val } \" ) print ( condition_expr ) if range_key_first_val : qry = mOHCR . query ( haz_sol_id , mOHCR . imt_loc_rlz_rk >= range_key_first_val , filter_condition = condition_expr ) else : qry = mOHCR . query ( haz_sol_id , mOHCR . imt_loc_rlz_rk >= \" \" , # lowest printable char in ascii table is SPACE. (NULL is first control) filter_condition = condition_expr , ) print ( f \"get_hazard_rlz_curves: qry { qry } \" ) for hit in qry : yield ( hit )","title":"get_hazard_rlz_curves()"},{"location":"api/#toshi_hazard_store.query.get_hazard_rlz_curves_v2","text":"Use mOHCR2.loc_agg_rk range key as much as possible. Source code in toshi_hazard_store/query.py 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 def get_hazard_rlz_curves_v2 ( haz_sol_id : str , imts : Iterable [ str ] = [], locs : Iterable [ str ] = [], rlzs : Iterable [ str ] = [], ) -> Iterator [ mOHCR2 ]: \"\"\"Use mOHCR2.loc_agg_rk range key as much as possible.\"\"\" range_key_first_val = \"\" condition_expr = None # if imts: # first_imt = sorted(imts)[0] # range_key_first_val += f\"{first_imt}\" # condition_expr = condition_expr & mOHCR.imt.is_in(*imts) if locs : condition_expr = condition_expr & mOHCR2 . loc . is_in ( * locs ) if rlzs : condition_expr = condition_expr & mOHCR2 . rlz . is_in ( * rlzs ) if locs : first_loc = sorted ( locs )[ 0 ] range_key_first_val += f \" { first_loc } \" if locs and rlzs : first_rlz = sorted ( rlzs )[ 0 ] range_key_first_val += f \": { first_rlz } \" print ( f \"range_key_first_val: { range_key_first_val } \" ) print ( condition_expr ) if range_key_first_val : qry = mOHCR2 . query ( haz_sol_id , mOHCR2 . loc_rlz_rk >= range_key_first_val , filter_condition = condition_expr ) else : qry = mOHCR2 . query ( haz_sol_id , mOHCR2 . loc_rlz_rk >= \" \" , # lowest printable char in ascii table is SPACE. (NULL is first control) filter_condition = condition_expr , ) print ( f \"get_hazard_rlz_curves_v2: qry { qry } \" ) for hit in qry : if imts : hit . values = list ( filter ( lambda x : x . imt in imts , hit . values )) yield ( hit )","title":"get_hazard_rlz_curves_v2()"},{"location":"api/#toshi_hazard_store.query.get_hazard_stats_curves","text":"Use ToshiOpenquakeHazardCurveStats.imt_loc_agg_rk range key as much as possible. Source code in toshi_hazard_store/query.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 def get_hazard_stats_curves ( haz_sol_id : str , imts : Iterable [ str ] = None , locs : Iterable [ str ] = None , aggs : Iterable [ str ] = None , ) -> Iterator [ mOHCS ]: \"\"\"Use ToshiOpenquakeHazardCurveStats.imt_loc_agg_rk range key as much as possible.\"\"\" range_key_first_val = \"\" condition_expr = None if imts : first_imt = sorted ( imts )[ 0 ] range_key_first_val += f \" { first_imt } \" condition_expr = condition_expr & mOHCS . imt . is_in ( * imts ) if locs : condition_expr = condition_expr & mOHCS . loc . is_in ( * locs ) if aggs : condition_expr = condition_expr & mOHCS . agg . is_in ( * aggs ) if imts and locs : first_loc = sorted ( locs )[ 0 ] range_key_first_val += f \": { first_loc } \" if imts and locs and aggs : first_agg = sorted ( aggs )[ 0 ] range_key_first_val += f \": { first_agg } \" print ( f \"range_key_first_val: { range_key_first_val } \" ) print ( condition_expr ) if range_key_first_val : qry = mOHCS . query ( haz_sol_id , mOHCS . imt_loc_agg_rk >= range_key_first_val , filter_condition = condition_expr ) else : qry = mOHCS . query ( haz_sol_id , mOHCS . imt_loc_agg_rk >= \" \" , # lowest printable char in ascii table is SPACE. (NULL is first control) filter_condition = condition_expr , ) print ( f \"get_hazard_stats_curves: qry { qry } \" ) for hit in qry : yield ( hit )","title":"get_hazard_stats_curves()"},{"location":"api/#toshi_hazard_store.query.get_hazard_stats_curves_v2","text":"Use mOHCS2.loc_agg_rk range key as much as possible. Source code in toshi_hazard_store/query.py 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 def get_hazard_stats_curves_v2 ( haz_sol_id : str , imts : Iterable [ str ] = [], locs : Iterable [ str ] = [], aggs : Iterable [ str ] = [], ) -> Iterator [ mOHCS2 ]: \"\"\"Use mOHCS2.loc_agg_rk range key as much as possible.\"\"\" range_key_first_val = \"\" condition_expr = None if locs : condition_expr = condition_expr & mOHCS2 . loc . is_in ( * locs ) if aggs : condition_expr = condition_expr & mOHCS2 . agg . is_in ( * aggs ) if locs : first_loc = sorted ( locs )[ 0 ] range_key_first_val += f \" { first_loc } \" if locs and aggs : first_agg = sorted ( aggs )[ 0 ] range_key_first_val += f \": { first_agg } \" print ( f \"range_key_first_val: { range_key_first_val } \" ) print ( condition_expr ) if range_key_first_val : qry = mOHCS2 . query ( haz_sol_id , mOHCS2 . loc_agg_rk >= range_key_first_val , filter_condition = condition_expr ) else : qry = mOHCS2 . query ( haz_sol_id , mOHCS2 . loc_agg_rk >= \" \" , # lowest printable char in ascii table is SPACE. (NULL is first control) filter_condition = condition_expr , ) print ( f \"get_hazard_stats_curves_v2: qry { qry } \" ) for hit in qry : if imts : hit . values = list ( filter ( lambda x : x . imt in imts , hit . values )) yield ( hit )","title":"get_hazard_stats_curves_v2()"},{"location":"api/#toshi_hazard_store.transform","text":"Helper functions to export an openquake calculation and save it with toshi-hazard-store.","title":"transform"},{"location":"api/#toshi_hazard_store.transform.export_meta","text":"Extract and same the meta data. Source code in toshi_hazard_store/transform.py 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 def export_meta ( toshi_id , dstore ): \"\"\"Extract and same the meta data.\"\"\" oq = dstore [ 'oqparam' ] sitemesh = get_sites ( dstore [ 'sitecol' ]) source_lt , gsim_lt , rlz_lt = parse_logic_tree_branches ( dstore . filename ) quantiles = [ str ( q ) for q in vars ( oq )[ 'quantiles' ]] + [ 'mean' ] # mean is default, other values come from the config df_len = 0 df_len += len ( source_lt . to_json ()) df_len += len ( gsim_lt . to_json ()) df_len += len ( rlz_lt . to_json ()) if df_len >= 300e3 : print ( 'WARNING: Dataframes for this job may be too large to store on DynamoDB.' ) obj = model . ToshiOpenquakeHazardMeta ( partition_key = \"ToshiOpenquakeHazardMeta\" , updated = dt . datetime . now ( tzutc ()), vs30 = oq . reference_vs30_value , # vs30 value haz_sol_id = toshi_id , imts = list ( oq . imtls . keys ()), # list of IMTs locs = [ tup [ 0 ] . decode () for tup in sitemesh . tolist ()], # list of Location codes # important configuration arguments aggs = quantiles , inv_time = vars ( oq )[ 'investigation_time' ], src_lt = source_lt . to_json (), # sources meta as DataFrame JSON gsim_lt = gsim_lt . to_json (), # gmpe meta as DataFrame JSON rlz_lt = rlz_lt . to_json (), # realization meta as DataFrame JSON ) obj . hazsol_vs30_rk = f \" { obj . haz_sol_id } : { obj . vs30 } \" obj . save ()","title":"export_meta()"},{"location":"api/#toshi_hazard_store.transform.parse_logic_tree_branches","text":"Extract the dataframes. Source code in toshi_hazard_store/transform.py 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 def parse_logic_tree_branches ( file_id ): \"\"\"Extract the dataframes.\"\"\" with h5py . File ( file_id ) as hf : # read and prepare the source model logic tree for documentation ### full_lt is a key that contains subkeys for each type of logic tree ### here we read the contents of source_model_lt into a dataframe source_lt = pd . DataFrame ( hf [ 'full_lt' ][ 'source_model_lt' ][:]) for col in source_lt . columns [: - 1 ]: source_lt . loc [:, col ] = source_lt [ col ] . str . decode ( 'ascii' ) # identify the source labels used in the realizations table source_lt . loc [:, 'branch_code' ] = [ x for x in BASE183 [ 0 : len ( source_lt )]] source_lt . set_index ( 'branch_code' , inplace = True ) # read and prepare the gsim logic tree for documentation ### full_lt is a key that contains subkeys for each type of logic tree ### here we read the contents of gsim_lt into a dataframe gsim_lt = pd . DataFrame ( hf [ 'full_lt' ][ 'gsim_lt' ][:]) for col in gsim_lt . columns [: - 1 ]: gsim_lt . loc [:, col ] = gsim_lt . loc [:, col ] . str . decode ( 'ascii' ) # # break up the gsim df into tectonic regions (one df per column of gsims in realization labels. e.g. A~AAA) # # the order of the dictionary is consistent with the order of the columns # gsim_lt_dict = {} # for i, trt in enumerate(np.unique(gsim_lt['trt'])): # df = gsim_lt[gsim_lt['trt'] == trt] # df.loc[:, 'branch_code'] = [x[1] for x in df['branch']] # df.set_index('branch_code', inplace=True) # ### the branch code used to be a user specified string from the gsim logic tree .xml # ### now the only way to identify which regionalization is used is to extract it manually # for j, x in zip(df.index, df['uncertainty']): # tags = re.split('\\\\[|\\\\]|\\nregion = \\\"|\\\"', x) # if len(tags) > 4: # df.loc[j, 'model name'] = f'{tags[1]}_{tags[3]}' # else: # df.loc[j, 'model name'] = tags[1] # gsim_lt_dict[i] = df # read and prep the realization record for documentation ### this one can be read into a df directly from the dstore's full_lt ### the column titled 'ordinal' is dropped, as it will be the same as the 0-n index dstore = datastore . read ( file_id ) rlz_lt = pd . DataFrame ( dstore [ 'full_lt' ] . rlzs ) . drop ( 'ordinal' , axis = 1 ) # # add to the rlt_lt to note which source models and which gsims were used for each branch # for i_rlz in rlz_lt.index: # # rlz name is in the form A~AAA, with a single source identifier followed by characters for each trt region # srm_code, gsim_codes = rlz_lt.loc[i_rlz, 'branch_path'].split('~') # # copy over the source label # rlz_lt.loc[i_rlz, 'source combination'] = source_lt.loc[srm_code, 'branch'] # # loop through the characters for the trt region and add the corresponding gsim name # for i, gsim_code in enumerate(gsim_codes): # trt, gsim = gsim_lt_dict[i].loc[gsim_code, ['trt', 'model name']] # rlz_lt.loc[i_rlz, trt] = gsim return source_lt , gsim_lt , rlz_lt","title":"parse_logic_tree_branches()"},{"location":"changelog/","text":"Changelog \u00b6 [0.4.0] - 2022-06-10 \u00b6 Added \u00b6 new V2 models for stats and rlzs. new get_hazard script for manual testing. extra test coverage with optional openquake install as DEV dependency. Changed \u00b6 meta dataframes are cut back to dstore defaults to minimise size. [0.3.2] - 2022-05-30 \u00b6 Added \u00b6 meta.aggs attribute meta.inv_tme attribute Changed \u00b6 store hazard can create tables. store hazard adds extra meta. store hazard truncates values for rlz and agg fields. make stats & rlz queries tolerant to ID-only form (fails with REAL dynamodb & not in mocks). [0.3.1] - 2022-05-29 \u00b6 Changed \u00b6 updated usage. [0.3.0] - 2022-05-28 \u00b6 Added \u00b6 store_hazard script for openquake systems. Changed \u00b6 tightened up model attributes names. [0.2.0] - 2022-05-27 \u00b6 Added \u00b6 query api improvements added meta table new query methods for meta and rlzs Changed \u00b6 moved vs30 from curves to meta updated docs [0.1.3] - 2022-05-26 \u00b6 Changed \u00b6 fixed mkdoc rendering of python & markdown. [0.1.2] - 2022-05-26 \u00b6 Changed \u00b6 fix poetry lockfile [0.1.1] - 2022-05-26 \u00b6 Added \u00b6 First release on PyPI. query and model modules providing basic support for openquake hazard stats curves only.","title":"Changelog"},{"location":"changelog/#changelog","text":"","title":"Changelog"},{"location":"changelog/#040---2022-06-10","text":"","title":"[0.4.0] - 2022-06-10"},{"location":"changelog/#added","text":"new V2 models for stats and rlzs. new get_hazard script for manual testing. extra test coverage with optional openquake install as DEV dependency.","title":"Added"},{"location":"changelog/#changed","text":"meta dataframes are cut back to dstore defaults to minimise size.","title":"Changed"},{"location":"changelog/#032---2022-05-30","text":"","title":"[0.3.2] - 2022-05-30"},{"location":"changelog/#added_1","text":"meta.aggs attribute meta.inv_tme attribute","title":"Added"},{"location":"changelog/#changed_1","text":"store hazard can create tables. store hazard adds extra meta. store hazard truncates values for rlz and agg fields. make stats & rlz queries tolerant to ID-only form (fails with REAL dynamodb & not in mocks).","title":"Changed"},{"location":"changelog/#031---2022-05-29","text":"","title":"[0.3.1] - 2022-05-29"},{"location":"changelog/#changed_2","text":"updated usage.","title":"Changed"},{"location":"changelog/#030---2022-05-28","text":"","title":"[0.3.0] - 2022-05-28"},{"location":"changelog/#added_2","text":"store_hazard script for openquake systems.","title":"Added"},{"location":"changelog/#changed_3","text":"tightened up model attributes names.","title":"Changed"},{"location":"changelog/#020---2022-05-27","text":"","title":"[0.2.0] - 2022-05-27"},{"location":"changelog/#added_3","text":"query api improvements added meta table new query methods for meta and rlzs","title":"Added"},{"location":"changelog/#changed_4","text":"moved vs30 from curves to meta updated docs","title":"Changed"},{"location":"changelog/#013---2022-05-26","text":"","title":"[0.1.3] - 2022-05-26"},{"location":"changelog/#changed_5","text":"fixed mkdoc rendering of python & markdown.","title":"Changed"},{"location":"changelog/#012---2022-05-26","text":"","title":"[0.1.2] - 2022-05-26"},{"location":"changelog/#changed_6","text":"fix poetry lockfile","title":"Changed"},{"location":"changelog/#011---2022-05-26","text":"","title":"[0.1.1] - 2022-05-26"},{"location":"changelog/#added_4","text":"First release on PyPI. query and model modules providing basic support for openquake hazard stats curves only.","title":"Added"},{"location":"contributing/","text":"Contributing \u00b6 Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. You can contribute in many ways: Types of Contributions \u00b6 Report Bugs \u00b6 Report bugs at https://github.com/GNS-Science/toshi-hazard-store/issues. If you are reporting a bug, please include: Your operating system name and version. Any details about your local setup that might be helpful in troubleshooting. Detailed steps to reproduce the bug. Fix Bugs \u00b6 Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it. Implement Features \u00b6 Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it. Write Documentation \u00b6 toshi-hazard-store could always use more documentation, whether as part of the official toshi-hazard-store docs, in docstrings, or even on the web in blog posts, articles, and such. Submit Feedback \u00b6 The best way to send feedback is to file an issue at https://github.com/GNS-Science/toshi-hazard-store/issues. If you are proposing a feature: Explain in detail how it would work. Keep the scope as narrow as possible, to make it easier to implement. Remember that this is a volunteer-driven project, and that contributions are welcome :) Get Started! \u00b6 Ready to contribute? Here's how to set up toshi-hazard-store for local development. Fork the toshi-hazard-store repo on GitHub. Clone your fork locally $ git clone git@github.com:your_name_here/toshi-hazard-store.git Ensure poetry is installed. Install dependencies and start your virtualenv: $ poetry install -E test -E doc -E dev Create a branch for local development: $ git checkout -b name-of-your-bugfix-or-feature Now you can make your changes locally. When you're done making changes, check that your changes pass the tests, including testing other Python versions, with tox: $ poetry run tox Commit your changes and push your branch to GitHub: $ git add . $ git commit -m \"Your detailed description of your changes.\" $ git push origin name-of-your-bugfix-or-feature Submit a pull request through the GitHub website. Pull Request Guidelines \u00b6 Before you submit a pull request, check that it meets these guidelines: The pull request should include tests. If the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring, and add the feature to the list in README.md. The pull request should work for Python 3.6, 3.7, 3.8 and 3.9. Check https://github.com/GNS-Science/toshi-hazard-store/actions and make sure that the tests pass for all supported Python versions. Tips \u00b6 $ poetry run pytest tests/test_toshi_hazard_store.py To run a subset of tests. Deploying \u00b6 A reminder for the maintainers on how to deploy. Make sure all your changes are committed (including an entry in CHANGELOG.md). Then run: $ poetry run bump2version patch # possible: major / minor / patch $ git push $ git push --tags GitHub Actions will then deploy to PyPI if tests pass.","title":"Contributing"},{"location":"contributing/#contributing","text":"Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. You can contribute in many ways:","title":"Contributing"},{"location":"contributing/#types-of-contributions","text":"","title":"Types of Contributions"},{"location":"contributing/#report-bugs","text":"Report bugs at https://github.com/GNS-Science/toshi-hazard-store/issues. If you are reporting a bug, please include: Your operating system name and version. Any details about your local setup that might be helpful in troubleshooting. Detailed steps to reproduce the bug.","title":"Report Bugs"},{"location":"contributing/#fix-bugs","text":"Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it.","title":"Fix Bugs"},{"location":"contributing/#implement-features","text":"Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it.","title":"Implement Features"},{"location":"contributing/#write-documentation","text":"toshi-hazard-store could always use more documentation, whether as part of the official toshi-hazard-store docs, in docstrings, or even on the web in blog posts, articles, and such.","title":"Write Documentation"},{"location":"contributing/#submit-feedback","text":"The best way to send feedback is to file an issue at https://github.com/GNS-Science/toshi-hazard-store/issues. If you are proposing a feature: Explain in detail how it would work. Keep the scope as narrow as possible, to make it easier to implement. Remember that this is a volunteer-driven project, and that contributions are welcome :)","title":"Submit Feedback"},{"location":"contributing/#get-started","text":"Ready to contribute? Here's how to set up toshi-hazard-store for local development. Fork the toshi-hazard-store repo on GitHub. Clone your fork locally $ git clone git@github.com:your_name_here/toshi-hazard-store.git Ensure poetry is installed. Install dependencies and start your virtualenv: $ poetry install -E test -E doc -E dev Create a branch for local development: $ git checkout -b name-of-your-bugfix-or-feature Now you can make your changes locally. When you're done making changes, check that your changes pass the tests, including testing other Python versions, with tox: $ poetry run tox Commit your changes and push your branch to GitHub: $ git add . $ git commit -m \"Your detailed description of your changes.\" $ git push origin name-of-your-bugfix-or-feature Submit a pull request through the GitHub website.","title":"Get Started!"},{"location":"contributing/#pull-request-guidelines","text":"Before you submit a pull request, check that it meets these guidelines: The pull request should include tests. If the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring, and add the feature to the list in README.md. The pull request should work for Python 3.6, 3.7, 3.8 and 3.9. Check https://github.com/GNS-Science/toshi-hazard-store/actions and make sure that the tests pass for all supported Python versions.","title":"Pull Request Guidelines"},{"location":"contributing/#tips","text":"$ poetry run pytest tests/test_toshi_hazard_store.py To run a subset of tests.","title":"Tips"},{"location":"contributing/#deploying","text":"A reminder for the maintainers on how to deploy. Make sure all your changes are committed (including an entry in CHANGELOG.md). Then run: $ poetry run bump2version patch # possible: major / minor / patch $ git push $ git push --tags GitHub Actions will then deploy to PyPI if tests pass.","title":"Deploying"},{"location":"installation/","text":"Installation \u00b6 Stable release \u00b6 To install toshi-hazard-store, run this command in your terminal: $ pip install toshi-hazard-store This is the preferred method to install toshi-hazard-store, as it will always install the most recent stable release. If you don't have pip installed, this Python installation guide can guide you through the process. From source \u00b6 The source for toshi-hazard-store can be downloaded from the Github repo . You can either clone the public repository: $ git clone git://github.com/GNS-Science/toshi-hazard-store Or download the tarball : $ curl -OJL https://github.com/GNS-Science/toshi-hazard-store/tarball/master Once you have a copy of the source, you can install it with: $ pip install .","title":"Installation"},{"location":"installation/#installation","text":"","title":"Installation"},{"location":"installation/#stable-release","text":"To install toshi-hazard-store, run this command in your terminal: $ pip install toshi-hazard-store This is the preferred method to install toshi-hazard-store, as it will always install the most recent stable release. If you don't have pip installed, this Python installation guide can guide you through the process.","title":"Stable release"},{"location":"installation/#from-source","text":"The source for toshi-hazard-store can be downloaded from the Github repo . You can either clone the public repository: $ git clone git://github.com/GNS-Science/toshi-hazard-store Or download the tarball : $ curl -OJL https://github.com/GNS-Science/toshi-hazard-store/tarball/master Once you have a copy of the source, you can install it with: $ pip install .","title":"From source"},{"location":"usage/","text":"Usage \u00b6 Environment & Authorisation pre-requisites \u00b6 TODO toshi-hazard-store (library) \u00b6 To use toshi-hazard-store in a project from toshi_hazard_store import query import pandas as pd import json TOSHI_ID = \"abcdef\" ## get some solution meta data ... for m in query.get_hazard_metadata(None, vs30_vals=[250, 350]): print(m.vs30, m.haz_sol_id, m.locs) source_lt = pd.read_json(m.src_lt) gsim_lt = pd.read_json(m.gsim_lt) rlzs_df = pd.read_json(m.rlz_lt) # realizations meta as pandas datframe. rlzs_dict = json.loads(m.rlz_lt) # realizations meta as dict. print(rlzs_dict) print(rlzs_df) ## get some agreggate curves for r in query.get_hazard_stats_curves(m.haz_sol_id, ['PGA'], ['WLG', 'QZN', 'CHC', 'DUD'], ['mean']): print(\"stat\", r.loc, r.values[0]) break ## get some realisation curves for r in query.get_hazard_rlz_curves(m.haz_sol_id, ['PGA'], ['WLG', 'QZN', 'CHC', 'DUD']): print(\"rlz\", r.loc, r.rlz, r.values[0] ) break store_hazard (script) \u00b6 TODO decribe usage of the upload script","title":"Usage"},{"location":"usage/#usage","text":"","title":"Usage"},{"location":"usage/#environment--authorisation-pre-requisites","text":"TODO","title":"Environment &amp; Authorisation pre-requisites"},{"location":"usage/#toshi-hazard-store-library","text":"To use toshi-hazard-store in a project from toshi_hazard_store import query import pandas as pd import json TOSHI_ID = \"abcdef\" ## get some solution meta data ... for m in query.get_hazard_metadata(None, vs30_vals=[250, 350]): print(m.vs30, m.haz_sol_id, m.locs) source_lt = pd.read_json(m.src_lt) gsim_lt = pd.read_json(m.gsim_lt) rlzs_df = pd.read_json(m.rlz_lt) # realizations meta as pandas datframe. rlzs_dict = json.loads(m.rlz_lt) # realizations meta as dict. print(rlzs_dict) print(rlzs_df) ## get some agreggate curves for r in query.get_hazard_stats_curves(m.haz_sol_id, ['PGA'], ['WLG', 'QZN', 'CHC', 'DUD'], ['mean']): print(\"stat\", r.loc, r.values[0]) break ## get some realisation curves for r in query.get_hazard_rlz_curves(m.haz_sol_id, ['PGA'], ['WLG', 'QZN', 'CHC', 'DUD']): print(\"rlz\", r.loc, r.rlz, r.values[0] ) break","title":"toshi-hazard-store (library)"},{"location":"usage/#store_hazard-script","text":"TODO decribe usage of the upload script","title":"store_hazard (script)"}]}