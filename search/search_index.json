{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"toshi-hazard-store \u00b6 plugin export module for openquake to manage hazard data in dynamodb. Documentation: https://GNS-Science.github.io/toshi-hazard-store GitHub: https://github.com/GNS-Science/toshi-hazard-store PyPI: https://pypi.org/project/toshi-hazard-store/ Free software: GPL-3.0-only Features \u00b6 TODO Credits \u00b6 This package was created with Cookiecutter and the waynerv/cookiecutter-pypackage project template.","title":"Home"},{"location":"#toshi-hazard-store","text":"plugin export module for openquake to manage hazard data in dynamodb. Documentation: https://GNS-Science.github.io/toshi-hazard-store GitHub: https://github.com/GNS-Science/toshi-hazard-store PyPI: https://pypi.org/project/toshi-hazard-store/ Free software: GPL-3.0-only","title":"toshi-hazard-store"},{"location":"#features","text":"TODO","title":"Features"},{"location":"#credits","text":"This package was created with Cookiecutter and the waynerv/cookiecutter-pypackage project template.","title":"Credits"},{"location":"api/","text":"Top-level package for toshi-hazard-store. config \u00b6 This module exports comfiguration for the current system. boolean_env ( environ_name , default = 'FALSE' ) \u00b6 Helper function. Source code in toshi_hazard_store/config.py 6 7 8 def boolean_env ( environ_name : str , default : str = 'FALSE' ) -> bool : \"\"\"Helper function.\"\"\" return bool ( os . getenv ( environ_name , default ) . upper () in [ \"1\" , \"Y\" , \"YES\" , \"TRUE\" ]) model \u00b6 This module defines the pynamodb tables used to store openquake data. LevelValuePairAttribute \u00b6 Bases: MapAttribute Store the IMT level and the POE value at the level. Source code in toshi_hazard_store/model.py 53 54 55 56 57 class LevelValuePairAttribute ( MapAttribute ): \"\"\"Store the IMT level and the POE value at the level.\"\"\" lvl = NumberAttribute ( null = False ) val = NumberAttribute ( null = False ) ToshiOpenquakeHazardCurveRlzs \u00b6 Bases: Model Stores the individual hazard realisation curves. Source code in toshi_hazard_store/model.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 class ToshiOpenquakeHazardCurveRlzs ( Model ): \"\"\"Stores the individual hazard realisation curves.\"\"\" class Meta : \"\"\"DynamoDB Metadata.\"\"\" billing_mode = 'PAY_PER_REQUEST' table_name = f \"ToshiOpenquakeHazardCurveRlzs- { DEPLOYMENT_STAGE } \" region = REGION if IS_OFFLINE : host = \"http://localhost:8000\" # pragma: no cover haz_sol_id = UnicodeAttribute ( hash_key = True ) imt_loc_rlz_rk = UnicodeAttribute ( range_key = True ) # TODO: check we can actually use this in queries! imt = UnicodeAttribute () loc = UnicodeAttribute () rlz = UnicodeAttribute () values = ListAttribute ( of = LevelValuePairAttribute ) version = VersionAttribute () Meta \u00b6 DynamoDB Metadata. Source code in toshi_hazard_store/model.py 63 64 65 66 67 68 69 70 class Meta : \"\"\"DynamoDB Metadata.\"\"\" billing_mode = 'PAY_PER_REQUEST' table_name = f \"ToshiOpenquakeHazardCurveRlzs- { DEPLOYMENT_STAGE } \" region = REGION if IS_OFFLINE : host = \"http://localhost:8000\" # pragma: no cover ToshiOpenquakeHazardCurveStats \u00b6 Bases: Model Stores the individual hazard statistical curves. Source code in toshi_hazard_store/model.py 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 class ToshiOpenquakeHazardCurveStats ( Model ): \"\"\"Stores the individual hazard statistical curves.\"\"\" class Meta : \"\"\"DynamoDB Metadata.\"\"\" billing_mode = 'PAY_PER_REQUEST' table_name = f \"ToshiOpenquakeHazardCurveStats- { DEPLOYMENT_STAGE } \" region = REGION if IS_OFFLINE : host = \"http://localhost:8000\" # pragma: no cover haz_sol_id = UnicodeAttribute ( hash_key = True ) imt_loc_agg_rk = UnicodeAttribute ( range_key = True ) imt = UnicodeAttribute () loc = UnicodeAttribute () agg = UnicodeAttribute () values = ListAttribute ( of = LevelValuePairAttribute ) version = VersionAttribute () Meta \u00b6 DynamoDB Metadata. Source code in toshi_hazard_store/model.py 86 87 88 89 90 91 92 93 class Meta : \"\"\"DynamoDB Metadata.\"\"\" billing_mode = 'PAY_PER_REQUEST' table_name = f \"ToshiOpenquakeHazardCurveStats- { DEPLOYMENT_STAGE } \" region = REGION if IS_OFFLINE : host = \"http://localhost:8000\" # pragma: no cover ToshiOpenquakeHazardMeta \u00b6 Bases: Model Stores metadata from the job configuration and the oq HDF5. Source code in toshi_hazard_store/model.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 class ToshiOpenquakeHazardMeta ( Model ): \"\"\"Stores metadata from the job configuration and the oq HDF5.\"\"\" class Meta : \"\"\"DynamoDB Metadata.\"\"\" billing_mode = 'PAY_PER_REQUEST' table_name = f \"ToshiOpenquakeHazardMeta- { DEPLOYMENT_STAGE } \" region = REGION if IS_OFFLINE : host = \"http://localhost:8000\" # pragma: no cover partition_key = UnicodeAttribute ( hash_key = True ) # a static value as we actually don't want to partition our data hazsol_vs30_rk = UnicodeAttribute ( range_key = True ) updated = UTCDateTimeAttribute () version = VersionAttribute () # known at configuration haz_sol_id = UnicodeAttribute () vs30 = NumberAttribute () # vs30 value imts = UnicodeSetAttribute () # list of IMTs locs = UnicodeSetAttribute () # list of Location codes srcs = UnicodeSetAttribute () # list of source model ids # extracted from the OQ HDF5 src_lt = JSONAttribute () # sources meta as DataFrame JSON gsim_lt = JSONAttribute () # gmpe meta as DataFrame JSON rlz_lt = JSONAttribute () # realization meta as DataFrame JSON Meta \u00b6 DynamoDB Metadata. Source code in toshi_hazard_store/model.py 25 26 27 28 29 30 31 32 class Meta : \"\"\"DynamoDB Metadata.\"\"\" billing_mode = 'PAY_PER_REQUEST' table_name = f \"ToshiOpenquakeHazardMeta- { DEPLOYMENT_STAGE } \" region = REGION if IS_OFFLINE : host = \"http://localhost:8000\" # pragma: no cover drop_tables () \u00b6 Drop the tables, if they exist. Source code in toshi_hazard_store/model.py 118 119 120 121 122 123 def drop_tables (): \"\"\"Drop the tables, if they exist.\"\"\" for table in tables : if table . exists (): # pragma: no cover table . delete_table () log . info ( f 'deleted table: { table } ' ) migrate () \u00b6 Create the tables, unless they exist already. Source code in toshi_hazard_store/model.py 109 110 111 112 113 114 115 def migrate (): \"\"\"Create the tables, unless they exist already.\"\"\" for table in tables : if not table . exists (): # pragma: no cover table . create_table ( wait = True ) print ( f \"Migrate created table: { table } \" ) log . info ( f \"Migrate created table: { table } \" ) query \u00b6 Queries for saving and retrieving openquake hazard results with convenience. batch_save_hcurve_rlzs ( toshi_id , models ) \u00b6 Save list of ToshiOpenquakeHazardCurveRlzs updating hash and range keys. Source code in toshi_hazard_store/query.py 16 17 18 19 20 21 22 def batch_save_hcurve_rlzs ( toshi_id , models : Iterable [ model . ToshiOpenquakeHazardCurveRlzs ]): \"\"\"Save list of ToshiOpenquakeHazardCurveRlzs updating hash and range keys.\"\"\" with model . ToshiOpenquakeHazardCurveRlzs . batch_write () as batch : for item in models : item . haz_sol_id = toshi_id item . imt_loc_rlz_rk = f \" { item . imt } : { item . loc } : { item . rlz } \" batch . save ( item ) batch_save_hcurve_stats ( toshi_id , models ) \u00b6 Save list of ToshiOpenquakeHazardCurveStats updating hash and range keys. Source code in toshi_hazard_store/query.py 7 8 9 10 11 12 13 def batch_save_hcurve_stats ( toshi_id : str , models : Iterable [ model . ToshiOpenquakeHazardCurveStats ]) -> None : \"\"\"Save list of ToshiOpenquakeHazardCurveStats updating hash and range keys.\"\"\" with model . ToshiOpenquakeHazardCurveStats . batch_write () as batch : for item in models : item . haz_sol_id = toshi_id item . imt_loc_agg_rk = f \" { item . imt } : { item . loc } : { item . agg } \" batch . save ( item ) get_hazard_metadata ( haz_sol_ids = None , vs30_vals = None ) \u00b6 Fetch ToshiOpenquakeHazardMeta based on criteria. Source code in toshi_hazard_store/query.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 def get_hazard_metadata ( haz_sol_ids : Iterable [ str ] = None , vs30_vals : Iterable [ int ] = None , ) -> Iterator [ mOHM ]: \"\"\"Fetch ToshiOpenquakeHazardMeta based on criteria.\"\"\" condition_expr = None if haz_sol_ids : condition_expr = condition_expr & mOHM . haz_sol_id . is_in ( * haz_sol_ids ) if vs30_vals : condition_expr = condition_expr & mOHM . vs30 . is_in ( * vs30_vals ) for hit in model . ToshiOpenquakeHazardMeta . query ( \"ToshiOpenquakeHazardMeta\" , filter_condition = condition_expr # NB the partition key is the table name! ): yield ( hit ) get_hazard_rlz_curves ( haz_sol_id , imts = None , locs = None , rlzs = None ) \u00b6 Use ToshiOpenquakeHazardCurveRlzs.imt_loc_agg_rk range key as much as possible. Source code in toshi_hazard_store/query.py 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 def get_hazard_rlz_curves ( haz_sol_id : str , imts : Iterable [ str ] = None , locs : Iterable [ str ] = None , rlzs : Iterable [ str ] = None , ) -> Iterator [ mOHCR ]: \"\"\"Use ToshiOpenquakeHazardCurveRlzs.imt_loc_agg_rk range key as much as possible.\"\"\" range_key_first_val = \"\" condition_expr = None if imts : first_imt = sorted ( imts )[ 0 ] range_key_first_val += f \" { first_imt } \" condition_expr = condition_expr & mOHCR . imt . is_in ( * imts ) if locs : condition_expr = condition_expr & mOHCR . loc . is_in ( * locs ) if rlzs : condition_expr = condition_expr & mOHCR . rlz . is_in ( * rlzs ) if imts and locs : first_loc = sorted ( locs )[ 0 ] range_key_first_val += f \": { first_loc } \" if imts and locs and rlzs : first_rlz = sorted ( rlzs )[ 0 ] range_key_first_val += f \": { first_rlz } \" print ( f \"range_key_first_val: { range_key_first_val } \" ) print ( condition_expr ) for hit in model . ToshiOpenquakeHazardCurveRlzs . query ( haz_sol_id , mOHCR . imt_loc_rlz_rk >= range_key_first_val , filter_condition = condition_expr ): yield ( hit ) get_hazard_stats_curves ( haz_sol_id , imts = None , locs = None , aggs = None ) \u00b6 Use ToshiOpenquakeHazardCurveStats.imt_loc_agg_rk range key as much as possible. Source code in toshi_hazard_store/query.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 def get_hazard_stats_curves ( haz_sol_id : str , imts : Iterable [ str ] = None , locs : Iterable [ str ] = None , aggs : Iterable [ str ] = None , ) -> Iterator [ mOHCS ]: \"\"\"Use ToshiOpenquakeHazardCurveStats.imt_loc_agg_rk range key as much as possible.\"\"\" range_key_first_val = \"\" condition_expr = None if imts : first_imt = sorted ( imts )[ 0 ] range_key_first_val += f \" { first_imt } \" condition_expr = condition_expr & mOHCS . imt . is_in ( * imts ) if locs : condition_expr = condition_expr & mOHCS . loc . is_in ( * locs ) if aggs : condition_expr = condition_expr & mOHCS . agg . is_in ( * aggs ) if imts and locs : first_loc = sorted ( locs )[ 0 ] range_key_first_val += f \": { first_loc } \" if imts and locs and aggs : first_agg = sorted ( aggs )[ 0 ] range_key_first_val += f \": { first_agg } \" for hit in model . ToshiOpenquakeHazardCurveStats . query ( haz_sol_id , mOHCS . imt_loc_agg_rk >= range_key_first_val , filter_condition = condition_expr ): yield ( hit )","title":"Modules"},{"location":"api/#toshi_hazard_store.config","text":"This module exports comfiguration for the current system.","title":"config"},{"location":"api/#toshi_hazard_store.config.boolean_env","text":"Helper function. Source code in toshi_hazard_store/config.py 6 7 8 def boolean_env ( environ_name : str , default : str = 'FALSE' ) -> bool : \"\"\"Helper function.\"\"\" return bool ( os . getenv ( environ_name , default ) . upper () in [ \"1\" , \"Y\" , \"YES\" , \"TRUE\" ])","title":"boolean_env()"},{"location":"api/#toshi_hazard_store.model","text":"This module defines the pynamodb tables used to store openquake data.","title":"model"},{"location":"api/#toshi_hazard_store.model.LevelValuePairAttribute","text":"Bases: MapAttribute Store the IMT level and the POE value at the level. Source code in toshi_hazard_store/model.py 53 54 55 56 57 class LevelValuePairAttribute ( MapAttribute ): \"\"\"Store the IMT level and the POE value at the level.\"\"\" lvl = NumberAttribute ( null = False ) val = NumberAttribute ( null = False )","title":"LevelValuePairAttribute"},{"location":"api/#toshi_hazard_store.model.ToshiOpenquakeHazardCurveRlzs","text":"Bases: Model Stores the individual hazard realisation curves. Source code in toshi_hazard_store/model.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 class ToshiOpenquakeHazardCurveRlzs ( Model ): \"\"\"Stores the individual hazard realisation curves.\"\"\" class Meta : \"\"\"DynamoDB Metadata.\"\"\" billing_mode = 'PAY_PER_REQUEST' table_name = f \"ToshiOpenquakeHazardCurveRlzs- { DEPLOYMENT_STAGE } \" region = REGION if IS_OFFLINE : host = \"http://localhost:8000\" # pragma: no cover haz_sol_id = UnicodeAttribute ( hash_key = True ) imt_loc_rlz_rk = UnicodeAttribute ( range_key = True ) # TODO: check we can actually use this in queries! imt = UnicodeAttribute () loc = UnicodeAttribute () rlz = UnicodeAttribute () values = ListAttribute ( of = LevelValuePairAttribute ) version = VersionAttribute ()","title":"ToshiOpenquakeHazardCurveRlzs"},{"location":"api/#toshi_hazard_store.model.ToshiOpenquakeHazardCurveRlzs.Meta","text":"DynamoDB Metadata. Source code in toshi_hazard_store/model.py 63 64 65 66 67 68 69 70 class Meta : \"\"\"DynamoDB Metadata.\"\"\" billing_mode = 'PAY_PER_REQUEST' table_name = f \"ToshiOpenquakeHazardCurveRlzs- { DEPLOYMENT_STAGE } \" region = REGION if IS_OFFLINE : host = \"http://localhost:8000\" # pragma: no cover","title":"Meta"},{"location":"api/#toshi_hazard_store.model.ToshiOpenquakeHazardCurveStats","text":"Bases: Model Stores the individual hazard statistical curves. Source code in toshi_hazard_store/model.py 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 class ToshiOpenquakeHazardCurveStats ( Model ): \"\"\"Stores the individual hazard statistical curves.\"\"\" class Meta : \"\"\"DynamoDB Metadata.\"\"\" billing_mode = 'PAY_PER_REQUEST' table_name = f \"ToshiOpenquakeHazardCurveStats- { DEPLOYMENT_STAGE } \" region = REGION if IS_OFFLINE : host = \"http://localhost:8000\" # pragma: no cover haz_sol_id = UnicodeAttribute ( hash_key = True ) imt_loc_agg_rk = UnicodeAttribute ( range_key = True ) imt = UnicodeAttribute () loc = UnicodeAttribute () agg = UnicodeAttribute () values = ListAttribute ( of = LevelValuePairAttribute ) version = VersionAttribute ()","title":"ToshiOpenquakeHazardCurveStats"},{"location":"api/#toshi_hazard_store.model.ToshiOpenquakeHazardCurveStats.Meta","text":"DynamoDB Metadata. Source code in toshi_hazard_store/model.py 86 87 88 89 90 91 92 93 class Meta : \"\"\"DynamoDB Metadata.\"\"\" billing_mode = 'PAY_PER_REQUEST' table_name = f \"ToshiOpenquakeHazardCurveStats- { DEPLOYMENT_STAGE } \" region = REGION if IS_OFFLINE : host = \"http://localhost:8000\" # pragma: no cover","title":"Meta"},{"location":"api/#toshi_hazard_store.model.ToshiOpenquakeHazardMeta","text":"Bases: Model Stores metadata from the job configuration and the oq HDF5. Source code in toshi_hazard_store/model.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 class ToshiOpenquakeHazardMeta ( Model ): \"\"\"Stores metadata from the job configuration and the oq HDF5.\"\"\" class Meta : \"\"\"DynamoDB Metadata.\"\"\" billing_mode = 'PAY_PER_REQUEST' table_name = f \"ToshiOpenquakeHazardMeta- { DEPLOYMENT_STAGE } \" region = REGION if IS_OFFLINE : host = \"http://localhost:8000\" # pragma: no cover partition_key = UnicodeAttribute ( hash_key = True ) # a static value as we actually don't want to partition our data hazsol_vs30_rk = UnicodeAttribute ( range_key = True ) updated = UTCDateTimeAttribute () version = VersionAttribute () # known at configuration haz_sol_id = UnicodeAttribute () vs30 = NumberAttribute () # vs30 value imts = UnicodeSetAttribute () # list of IMTs locs = UnicodeSetAttribute () # list of Location codes srcs = UnicodeSetAttribute () # list of source model ids # extracted from the OQ HDF5 src_lt = JSONAttribute () # sources meta as DataFrame JSON gsim_lt = JSONAttribute () # gmpe meta as DataFrame JSON rlz_lt = JSONAttribute () # realization meta as DataFrame JSON","title":"ToshiOpenquakeHazardMeta"},{"location":"api/#toshi_hazard_store.model.ToshiOpenquakeHazardMeta.Meta","text":"DynamoDB Metadata. Source code in toshi_hazard_store/model.py 25 26 27 28 29 30 31 32 class Meta : \"\"\"DynamoDB Metadata.\"\"\" billing_mode = 'PAY_PER_REQUEST' table_name = f \"ToshiOpenquakeHazardMeta- { DEPLOYMENT_STAGE } \" region = REGION if IS_OFFLINE : host = \"http://localhost:8000\" # pragma: no cover","title":"Meta"},{"location":"api/#toshi_hazard_store.model.drop_tables","text":"Drop the tables, if they exist. Source code in toshi_hazard_store/model.py 118 119 120 121 122 123 def drop_tables (): \"\"\"Drop the tables, if they exist.\"\"\" for table in tables : if table . exists (): # pragma: no cover table . delete_table () log . info ( f 'deleted table: { table } ' )","title":"drop_tables()"},{"location":"api/#toshi_hazard_store.model.migrate","text":"Create the tables, unless they exist already. Source code in toshi_hazard_store/model.py 109 110 111 112 113 114 115 def migrate (): \"\"\"Create the tables, unless they exist already.\"\"\" for table in tables : if not table . exists (): # pragma: no cover table . create_table ( wait = True ) print ( f \"Migrate created table: { table } \" ) log . info ( f \"Migrate created table: { table } \" )","title":"migrate()"},{"location":"api/#toshi_hazard_store.query","text":"Queries for saving and retrieving openquake hazard results with convenience.","title":"query"},{"location":"api/#toshi_hazard_store.query.batch_save_hcurve_rlzs","text":"Save list of ToshiOpenquakeHazardCurveRlzs updating hash and range keys. Source code in toshi_hazard_store/query.py 16 17 18 19 20 21 22 def batch_save_hcurve_rlzs ( toshi_id , models : Iterable [ model . ToshiOpenquakeHazardCurveRlzs ]): \"\"\"Save list of ToshiOpenquakeHazardCurveRlzs updating hash and range keys.\"\"\" with model . ToshiOpenquakeHazardCurveRlzs . batch_write () as batch : for item in models : item . haz_sol_id = toshi_id item . imt_loc_rlz_rk = f \" { item . imt } : { item . loc } : { item . rlz } \" batch . save ( item )","title":"batch_save_hcurve_rlzs()"},{"location":"api/#toshi_hazard_store.query.batch_save_hcurve_stats","text":"Save list of ToshiOpenquakeHazardCurveStats updating hash and range keys. Source code in toshi_hazard_store/query.py 7 8 9 10 11 12 13 def batch_save_hcurve_stats ( toshi_id : str , models : Iterable [ model . ToshiOpenquakeHazardCurveStats ]) -> None : \"\"\"Save list of ToshiOpenquakeHazardCurveStats updating hash and range keys.\"\"\" with model . ToshiOpenquakeHazardCurveStats . batch_write () as batch : for item in models : item . haz_sol_id = toshi_id item . imt_loc_agg_rk = f \" { item . imt } : { item . loc } : { item . agg } \" batch . save ( item )","title":"batch_save_hcurve_stats()"},{"location":"api/#toshi_hazard_store.query.get_hazard_metadata","text":"Fetch ToshiOpenquakeHazardMeta based on criteria. Source code in toshi_hazard_store/query.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 def get_hazard_metadata ( haz_sol_ids : Iterable [ str ] = None , vs30_vals : Iterable [ int ] = None , ) -> Iterator [ mOHM ]: \"\"\"Fetch ToshiOpenquakeHazardMeta based on criteria.\"\"\" condition_expr = None if haz_sol_ids : condition_expr = condition_expr & mOHM . haz_sol_id . is_in ( * haz_sol_ids ) if vs30_vals : condition_expr = condition_expr & mOHM . vs30 . is_in ( * vs30_vals ) for hit in model . ToshiOpenquakeHazardMeta . query ( \"ToshiOpenquakeHazardMeta\" , filter_condition = condition_expr # NB the partition key is the table name! ): yield ( hit )","title":"get_hazard_metadata()"},{"location":"api/#toshi_hazard_store.query.get_hazard_rlz_curves","text":"Use ToshiOpenquakeHazardCurveRlzs.imt_loc_agg_rk range key as much as possible. Source code in toshi_hazard_store/query.py 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 def get_hazard_rlz_curves ( haz_sol_id : str , imts : Iterable [ str ] = None , locs : Iterable [ str ] = None , rlzs : Iterable [ str ] = None , ) -> Iterator [ mOHCR ]: \"\"\"Use ToshiOpenquakeHazardCurveRlzs.imt_loc_agg_rk range key as much as possible.\"\"\" range_key_first_val = \"\" condition_expr = None if imts : first_imt = sorted ( imts )[ 0 ] range_key_first_val += f \" { first_imt } \" condition_expr = condition_expr & mOHCR . imt . is_in ( * imts ) if locs : condition_expr = condition_expr & mOHCR . loc . is_in ( * locs ) if rlzs : condition_expr = condition_expr & mOHCR . rlz . is_in ( * rlzs ) if imts and locs : first_loc = sorted ( locs )[ 0 ] range_key_first_val += f \": { first_loc } \" if imts and locs and rlzs : first_rlz = sorted ( rlzs )[ 0 ] range_key_first_val += f \": { first_rlz } \" print ( f \"range_key_first_val: { range_key_first_val } \" ) print ( condition_expr ) for hit in model . ToshiOpenquakeHazardCurveRlzs . query ( haz_sol_id , mOHCR . imt_loc_rlz_rk >= range_key_first_val , filter_condition = condition_expr ): yield ( hit )","title":"get_hazard_rlz_curves()"},{"location":"api/#toshi_hazard_store.query.get_hazard_stats_curves","text":"Use ToshiOpenquakeHazardCurveStats.imt_loc_agg_rk range key as much as possible. Source code in toshi_hazard_store/query.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 def get_hazard_stats_curves ( haz_sol_id : str , imts : Iterable [ str ] = None , locs : Iterable [ str ] = None , aggs : Iterable [ str ] = None , ) -> Iterator [ mOHCS ]: \"\"\"Use ToshiOpenquakeHazardCurveStats.imt_loc_agg_rk range key as much as possible.\"\"\" range_key_first_val = \"\" condition_expr = None if imts : first_imt = sorted ( imts )[ 0 ] range_key_first_val += f \" { first_imt } \" condition_expr = condition_expr & mOHCS . imt . is_in ( * imts ) if locs : condition_expr = condition_expr & mOHCS . loc . is_in ( * locs ) if aggs : condition_expr = condition_expr & mOHCS . agg . is_in ( * aggs ) if imts and locs : first_loc = sorted ( locs )[ 0 ] range_key_first_val += f \": { first_loc } \" if imts and locs and aggs : first_agg = sorted ( aggs )[ 0 ] range_key_first_val += f \": { first_agg } \" for hit in model . ToshiOpenquakeHazardCurveStats . query ( haz_sol_id , mOHCS . imt_loc_agg_rk >= range_key_first_val , filter_condition = condition_expr ): yield ( hit )","title":"get_hazard_stats_curves()"},{"location":"changelog/","text":"Changelog \u00b6 [0.3.1] - 2022-05-29 \u00b6 Changed \u00b6 updated usage. [0.3.0] - 2022-05-28 \u00b6 Added \u00b6 store_hazard script for openquake systems. Changed \u00b6 tightened up model attributes names. [0.2.0] - 2022-05-27 \u00b6 Added \u00b6 query api improvements added meta table new query methods for meta and rlzs Changed \u00b6 moved vs30 from curves to meta updated docs [0.1.3] - 2022-05-26 \u00b6 Changed \u00b6 fixed mkdoc rendering of python & markdown. [0.1.2] - 2022-05-26 \u00b6 Changed \u00b6 fix poetry lockfile [0.1.1] - 2022-05-26 \u00b6 Added \u00b6 First release on PyPI. query and model modules providing basic support for openquake hazard stats curves only.","title":"Changelog"},{"location":"changelog/#changelog","text":"","title":"Changelog"},{"location":"changelog/#031---2022-05-29","text":"","title":"[0.3.1] - 2022-05-29"},{"location":"changelog/#changed","text":"updated usage.","title":"Changed"},{"location":"changelog/#030---2022-05-28","text":"","title":"[0.3.0] - 2022-05-28"},{"location":"changelog/#added","text":"store_hazard script for openquake systems.","title":"Added"},{"location":"changelog/#changed_1","text":"tightened up model attributes names.","title":"Changed"},{"location":"changelog/#020---2022-05-27","text":"","title":"[0.2.0] - 2022-05-27"},{"location":"changelog/#added_1","text":"query api improvements added meta table new query methods for meta and rlzs","title":"Added"},{"location":"changelog/#changed_2","text":"moved vs30 from curves to meta updated docs","title":"Changed"},{"location":"changelog/#013---2022-05-26","text":"","title":"[0.1.3] - 2022-05-26"},{"location":"changelog/#changed_3","text":"fixed mkdoc rendering of python & markdown.","title":"Changed"},{"location":"changelog/#012---2022-05-26","text":"","title":"[0.1.2] - 2022-05-26"},{"location":"changelog/#changed_4","text":"fix poetry lockfile","title":"Changed"},{"location":"changelog/#011---2022-05-26","text":"","title":"[0.1.1] - 2022-05-26"},{"location":"changelog/#added_2","text":"First release on PyPI. query and model modules providing basic support for openquake hazard stats curves only.","title":"Added"},{"location":"contributing/","text":"Contributing \u00b6 Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. You can contribute in many ways: Types of Contributions \u00b6 Report Bugs \u00b6 Report bugs at https://github.com/GNS-Science/toshi-hazard-store/issues. If you are reporting a bug, please include: Your operating system name and version. Any details about your local setup that might be helpful in troubleshooting. Detailed steps to reproduce the bug. Fix Bugs \u00b6 Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it. Implement Features \u00b6 Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it. Write Documentation \u00b6 toshi-hazard-store could always use more documentation, whether as part of the official toshi-hazard-store docs, in docstrings, or even on the web in blog posts, articles, and such. Submit Feedback \u00b6 The best way to send feedback is to file an issue at https://github.com/GNS-Science/toshi-hazard-store/issues. If you are proposing a feature: Explain in detail how it would work. Keep the scope as narrow as possible, to make it easier to implement. Remember that this is a volunteer-driven project, and that contributions are welcome :) Get Started! \u00b6 Ready to contribute? Here's how to set up toshi-hazard-store for local development. Fork the toshi-hazard-store repo on GitHub. Clone your fork locally $ git clone git@github.com:your_name_here/toshi-hazard-store.git Ensure poetry is installed. Install dependencies and start your virtualenv: $ poetry install -E test -E doc -E dev Create a branch for local development: $ git checkout -b name-of-your-bugfix-or-feature Now you can make your changes locally. When you're done making changes, check that your changes pass the tests, including testing other Python versions, with tox: $ poetry run tox Commit your changes and push your branch to GitHub: $ git add . $ git commit -m \"Your detailed description of your changes.\" $ git push origin name-of-your-bugfix-or-feature Submit a pull request through the GitHub website. Pull Request Guidelines \u00b6 Before you submit a pull request, check that it meets these guidelines: The pull request should include tests. If the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring, and add the feature to the list in README.md. The pull request should work for Python 3.6, 3.7, 3.8 and 3.9. Check https://github.com/GNS-Science/toshi-hazard-store/actions and make sure that the tests pass for all supported Python versions. Tips \u00b6 $ poetry run pytest tests/test_toshi_hazard_store.py To run a subset of tests. Deploying \u00b6 A reminder for the maintainers on how to deploy. Make sure all your changes are committed (including an entry in CHANGELOG.md). Then run: $ poetry run bump2version patch # possible: major / minor / patch $ git push $ git push --tags GitHub Actions will then deploy to PyPI if tests pass.","title":"Contributing"},{"location":"contributing/#contributing","text":"Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. You can contribute in many ways:","title":"Contributing"},{"location":"contributing/#types-of-contributions","text":"","title":"Types of Contributions"},{"location":"contributing/#report-bugs","text":"Report bugs at https://github.com/GNS-Science/toshi-hazard-store/issues. If you are reporting a bug, please include: Your operating system name and version. Any details about your local setup that might be helpful in troubleshooting. Detailed steps to reproduce the bug.","title":"Report Bugs"},{"location":"contributing/#fix-bugs","text":"Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it.","title":"Fix Bugs"},{"location":"contributing/#implement-features","text":"Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it.","title":"Implement Features"},{"location":"contributing/#write-documentation","text":"toshi-hazard-store could always use more documentation, whether as part of the official toshi-hazard-store docs, in docstrings, or even on the web in blog posts, articles, and such.","title":"Write Documentation"},{"location":"contributing/#submit-feedback","text":"The best way to send feedback is to file an issue at https://github.com/GNS-Science/toshi-hazard-store/issues. If you are proposing a feature: Explain in detail how it would work. Keep the scope as narrow as possible, to make it easier to implement. Remember that this is a volunteer-driven project, and that contributions are welcome :)","title":"Submit Feedback"},{"location":"contributing/#get-started","text":"Ready to contribute? Here's how to set up toshi-hazard-store for local development. Fork the toshi-hazard-store repo on GitHub. Clone your fork locally $ git clone git@github.com:your_name_here/toshi-hazard-store.git Ensure poetry is installed. Install dependencies and start your virtualenv: $ poetry install -E test -E doc -E dev Create a branch for local development: $ git checkout -b name-of-your-bugfix-or-feature Now you can make your changes locally. When you're done making changes, check that your changes pass the tests, including testing other Python versions, with tox: $ poetry run tox Commit your changes and push your branch to GitHub: $ git add . $ git commit -m \"Your detailed description of your changes.\" $ git push origin name-of-your-bugfix-or-feature Submit a pull request through the GitHub website.","title":"Get Started!"},{"location":"contributing/#pull-request-guidelines","text":"Before you submit a pull request, check that it meets these guidelines: The pull request should include tests. If the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring, and add the feature to the list in README.md. The pull request should work for Python 3.6, 3.7, 3.8 and 3.9. Check https://github.com/GNS-Science/toshi-hazard-store/actions and make sure that the tests pass for all supported Python versions.","title":"Pull Request Guidelines"},{"location":"contributing/#tips","text":"$ poetry run pytest tests/test_toshi_hazard_store.py To run a subset of tests.","title":"Tips"},{"location":"contributing/#deploying","text":"A reminder for the maintainers on how to deploy. Make sure all your changes are committed (including an entry in CHANGELOG.md). Then run: $ poetry run bump2version patch # possible: major / minor / patch $ git push $ git push --tags GitHub Actions will then deploy to PyPI if tests pass.","title":"Deploying"},{"location":"installation/","text":"Installation \u00b6 Stable release \u00b6 To install toshi-hazard-store, run this command in your terminal: $ pip install toshi-hazard-store This is the preferred method to install toshi-hazard-store, as it will always install the most recent stable release. If you don't have pip installed, this Python installation guide can guide you through the process. From source \u00b6 The source for toshi-hazard-store can be downloaded from the Github repo . You can either clone the public repository: $ git clone git://github.com/GNS-Science/toshi-hazard-store Or download the tarball : $ curl -OJL https://github.com/GNS-Science/toshi-hazard-store/tarball/master Once you have a copy of the source, you can install it with: $ pip install .","title":"Installation"},{"location":"installation/#installation","text":"","title":"Installation"},{"location":"installation/#stable-release","text":"To install toshi-hazard-store, run this command in your terminal: $ pip install toshi-hazard-store This is the preferred method to install toshi-hazard-store, as it will always install the most recent stable release. If you don't have pip installed, this Python installation guide can guide you through the process.","title":"Stable release"},{"location":"installation/#from-source","text":"The source for toshi-hazard-store can be downloaded from the Github repo . You can either clone the public repository: $ git clone git://github.com/GNS-Science/toshi-hazard-store Or download the tarball : $ curl -OJL https://github.com/GNS-Science/toshi-hazard-store/tarball/master Once you have a copy of the source, you can install it with: $ pip install .","title":"From source"},{"location":"usage/","text":"Usage \u00b6 Environment & Authorisation pre-requisites \u00b6 TODO toshi-hazard-store (library) \u00b6 To use toshi-hazard-store in a project from toshi_hazard_store import query import pandas as pd import json TOSHI_ID = \"abcdef\" ## get some solution meta data ... for m in query.get_hazard_metadata(None, vs30_vals=[250, 350]): print(m.vs30, m.haz_sol_id, m.locs) source_lt = pd.read_json(m.src_lt) gsim_lt = pd.read_json(m.gsim_lt) rlzs_df = pd.read_json(m.rlz_lt) # realizations meta as pandas datframe. rlzs_dict = json.loads(m.rlz_lt) # realizations meta as dict. print(rlzs_dict) print(rlzs_df) ## get some agreggate curves for r in query.get_hazard_stats_curves(m.haz_sol_id, ['PGA'], ['WLG', 'QZN', 'CHC', 'DUD'], ['mean']): print(\"stat\", r.loc, r.values[0]) break ## get some realisation curves for r in query.get_hazard_rlz_curves(m.haz_sol_id, ['PGA'], ['WLG', 'QZN', 'CHC', 'DUD']): print(\"rlz\", r.loc, r.rlz, r.values[0] ) break store_hazard (script) \u00b6 TODO decribe usage of the upload script","title":"Usage"},{"location":"usage/#usage","text":"","title":"Usage"},{"location":"usage/#environment--authorisation-pre-requisites","text":"TODO","title":"Environment &amp; Authorisation pre-requisites"},{"location":"usage/#toshi-hazard-store-library","text":"To use toshi-hazard-store in a project from toshi_hazard_store import query import pandas as pd import json TOSHI_ID = \"abcdef\" ## get some solution meta data ... for m in query.get_hazard_metadata(None, vs30_vals=[250, 350]): print(m.vs30, m.haz_sol_id, m.locs) source_lt = pd.read_json(m.src_lt) gsim_lt = pd.read_json(m.gsim_lt) rlzs_df = pd.read_json(m.rlz_lt) # realizations meta as pandas datframe. rlzs_dict = json.loads(m.rlz_lt) # realizations meta as dict. print(rlzs_dict) print(rlzs_df) ## get some agreggate curves for r in query.get_hazard_stats_curves(m.haz_sol_id, ['PGA'], ['WLG', 'QZN', 'CHC', 'DUD'], ['mean']): print(\"stat\", r.loc, r.values[0]) break ## get some realisation curves for r in query.get_hazard_rlz_curves(m.haz_sol_id, ['PGA'], ['WLG', 'QZN', 'CHC', 'DUD']): print(\"rlz\", r.loc, r.rlz, r.values[0] ) break","title":"toshi-hazard-store (library)"},{"location":"usage/#store_hazard-script","text":"TODO decribe usage of the upload script","title":"store_hazard (script)"}]}